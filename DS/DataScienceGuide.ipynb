{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module-2 Python\n",
        "\n"
      ],
      "metadata": {
        "id": "X9tj-NENMzjw"
      },
      "id": "X9tj-NENMzjw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Specification\n",
        "- use `!` command in front to use local terminal type of thing\n",
        "- also whenever you do `!ls` you can see that the file folder (sample_data) which google collab has provided shows meaning all your files are starting from this directory"
      ],
      "metadata": {
        "id": "ri2vDmPLPcND"
      },
      "id": "ri2vDmPLPcND"
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo\n",
        "!cat /proc/meminfo\n",
        "!ls\n",
        "!cd / && pwd && ls"
      ],
      "metadata": {
        "id": "IOPA35kXNHWj"
      },
      "id": "IOPA35kXNHWj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Libraries\n",
        "- use !pip install library ex. pip install pandas\n",
        "- import pandas as py and use inside code"
      ],
      "metadata": {
        "id": "mbQnn1keOU5g"
      },
      "id": "mbQnn1keOU5g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Basics"
      ],
      "metadata": {
        "id": "eJiCgRtdPrxI"
      },
      "id": "eJiCgRtdPrxI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Types:\n",
        "- int\n",
        "- float\n",
        "- str (Can use \"\" or '' both to declare string)\n",
        "- complex\n",
        "- boolean (True and False)\n",
        "  - Comparator (< > == can use along with boolean)\n",
        "- using print() and type() funtions\n",
        "  - print(\"shubham\"*5) then 5 times print"
      ],
      "metadata": {
        "id": "5tXdUErSPwoV"
      },
      "id": "5tXdUErSPwoV"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"mergin\"+\"this\")"
      ],
      "metadata": {
        "id": "WjTpuMpXP5am"
      },
      "id": "WjTpuMpXP5am",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(8+3)"
      ],
      "metadata": {
        "id": "6OQqSWhjP-Jf"
      },
      "id": "6OQqSWhjP-Jf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(8)\n",
        "type(8.3)\n",
        "type(\"Syrting\")"
      ],
      "metadata": {
        "id": "dcF-8EZiQBZS"
      },
      "id": "dcF-8EZiQBZS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= 1+3j\n",
        "print(a)\n",
        "type(a)\n",
        "\n",
        "b=True\n",
        "c=False\n",
        "type(c)\n",
        "\n",
        "d= 7>3\n",
        "print(d)"
      ],
      "metadata": {
        "id": "8MI2TYFdSm19"
      },
      "id": "8MI2TYFdSm19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slicing & Steping & Concatenation A String\n",
        "- Index starts with zero in python\n",
        "- Stepping ek step mein string trim karega\n",
        "- styrinA +stringB concatination"
      ],
      "metadata": {
        "id": "7cCtlrn6T63I"
      },
      "id": "7cCtlrn6T63I"
    },
    {
      "cell_type": "code",
      "source": [
        "a= \"shubham\"\n",
        "print(a[1:3]) #starting from 1 to 3 wale\n",
        "print(a[0:5:2]) #2 is the step here"
      ],
      "metadata": {
        "id": "ctdh2QJLUCy-"
      },
      "id": "ctdh2QJLUCy-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants and Variables\n",
        "- variables can be redeclared while constants cannot\n",
        "- multiple values to multiple varibales use `,` separated declaration\n",
        "- single values to multiple varaible use `=`"
      ],
      "metadata": {
        "id": "7CrvIKI0QiCI"
      },
      "id": "7CrvIKI0QiCI"
    },
    {
      "cell_type": "code",
      "source": [
        "variable1 = \"toppo\"\n",
        "print(variable1)\n",
        "var1, var2 = \"shubham\", 5\n",
        "print(var1)\n",
        "print(var2)\n",
        "\n",
        "x=y=z = 5\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "6nDb5P50QpHI"
      },
      "id": "6nDb5P50QpHI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Function and Changing Datatype in Python"
      ],
      "metadata": {
        "id": "nLnStllsRikB"
      },
      "id": "nLnStllsRikB"
    },
    {
      "cell_type": "code",
      "source": [
        "num1 = int(input(\"Enter number1 here :\"))\n",
        "num2 = int(input(\"Enter number2 here :\"))\n",
        "# By defaut input return string -> Convert into int -> int(string)\n",
        "sum= num1+num2\n",
        "print(sum)\n",
        "\n",
        "integer=5\n",
        "type(integer)\n",
        "#Converting to float\n",
        "floatvalue = float(integer)\n",
        "print(floatvalue)"
      ],
      "metadata": {
        "id": "vudlA9aARl9N"
      },
      "id": "vudlA9aARl9N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Types of objects in Python\n",
        "1) Mutable : Can be changed once created\n",
        "- List, Set, Dictionary\n",
        "  - List allows duplicate values\n",
        "  - List append() to add element\n",
        "  - list[index] to access element Index starts with zero\n",
        "  - len(list) -to get length of list\n",
        "\n",
        "2) Immutable\n",
        "- int, float, str, bool, tuple"
      ],
      "metadata": {
        "id": "FQe7U6x4XXR1"
      },
      "id": "FQe7U6x4XXR1"
    },
    {
      "cell_type": "code",
      "source": [
        "# LIST -> Changebale\n",
        "# Use [brackets] and can have multiple data types\n",
        "my_list=[1,2,\"English\"]\n",
        "print(my_list)\n",
        "type(my_list)\n",
        "\n",
        "#declaring values i using loop\n",
        "python_list=[i for i in range(10000)]\n",
        "\n",
        "# Add Element in list\n",
        "my_list.append(90)\n",
        "print(my_list)\n",
        "\n",
        "#Indexing a list\n",
        "print(my_list[2])\n",
        "\n",
        "#Length\n",
        "print(len(my_list))\n",
        "\n",
        "# Deleting a index\n",
        "del my_list[0]\n",
        "print(my_list)\n",
        "\n",
        "#Empty List\n",
        "new_list=[]\n",
        "new_list.append(400)\n",
        "\n",
        "#Joining two list\n",
        "join_list= my_list+new_list\n",
        "print(join_list)\n"
      ],
      "metadata": {
        "id": "iXierqm8Xnp4"
      },
      "id": "iXierqm8Xnp4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuple -> unchangebable\n",
        "# Use (brackets) + allows multiple data type\n",
        "tuple1= (1,2,\"String\")\n",
        "print(tuple1)\n",
        "\n",
        "#Convert List to Tuple\n",
        "my_list=[2,3]\n",
        "my_tuple=tuple(my_list)\n",
        "print(my_tuple)\n",
        "\n",
        "#Indexing in tuple\n",
        "print(my_tuple[1])\n",
        "\n",
        "#Length\n",
        "print(len(my_tuple))\n",
        "\n",
        "#Immutable can't change\n",
        "# my_tuple.append(5) #Won't work\n",
        "\n"
      ],
      "metadata": {
        "id": "b6Pjh2UeYj35"
      },
      "id": "b6Pjh2UeYj35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set -> Mutable + Doesn't allow duplicates\n",
        "# Use {bracket} + NoIndex here [index] wont work\n",
        "\n",
        "mySet= {1,2,3,4}\n",
        "print(mySet)\n",
        "print(len(mySet))\n",
        "# print(mySet[1]) #Throw Error\n",
        "\n",
        "#Convert List TO a Set\n",
        "listt=[7,8,9,9,9,9]\n",
        "convert=set(listt)\n",
        "print(convert)"
      ],
      "metadata": {
        "id": "7QJ6xlfoAFrd"
      },
      "id": "7QJ6xlfoAFrd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dictionary -> Key Value Pair + Duplicate Key not allowed\n",
        "my_dict={\"a\":40,\"b\":\"Value\"}\n",
        "print(my_dict)\n",
        "print(type(my_dict))\n",
        "print(my_dict[\"a\"])\n",
        "\n",
        "my_dict2={\"a\":40,\"b\":\"Value\",\"a\":\"other\"}\n",
        "my_dict2[\"c\"]=\"declaring new value\"\n",
        "\n",
        "#delete key from dictionary\n",
        "del my_dict2[\"b\"]\n",
        "print(my_dict2)\n",
        "my_dict2.get(\"c\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BraKovxCAaQF"
      },
      "id": "BraKovxCAaQF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operators In Python\n",
        "- Maths -> + - / * **(power)\n",
        "- Assignment Operator += -= /= %= **=\n",
        "- Comparision Operator == != <= >=\n",
        "- Logical Operator (and or not)\n",
        "- Identity Operator (is is not) values match\n",
        "- Membership operator (in not in) list match values"
      ],
      "metadata": {
        "id": "wg3NlQBlByYt"
      },
      "id": "wg3NlQBlByYt"
    },
    {
      "cell_type": "code",
      "source": [
        "#Maths\n",
        "num1=5\n",
        "num2=10\n",
        "print(\"sum = \",num1**num2)\n",
        "a=0\n",
        "a+=num1\n",
        "\n",
        "#Assignment Operator\n",
        "print(\"sum = \",a)\n",
        "\n",
        "#Comparision Operator\n",
        "print(num1<=num2)\n",
        "\n",
        "#Logical Operator\n",
        "print(num1 and num2) #This return and operation on number\n",
        "print(num1>10 or num2<20)\n",
        "print(not(num1>10 or num2<20))\n",
        "\n",
        "#Identity Operator\n",
        "a=5\n",
        "b=5\n",
        "print(a is not b)\n",
        "\n",
        "# Membership operator\n",
        "listt=[1,2,3,4,5]\n",
        "print(a not in listt)\n"
      ],
      "metadata": {
        "id": "REHCDK9yCKfK"
      },
      "id": "REHCDK9yCKfK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If Else Loops Function\n",
        "- for index,value in enemerate(x):\n",
        "  x[index] type"
      ],
      "metadata": {
        "id": "cYCKmvhdE2rj"
      },
      "id": "cYCKmvhdE2rj"
    },
    {
      "cell_type": "code",
      "source": [
        "#If Else Condition\n",
        "a=1\n",
        "b=1\n",
        "if(a<b):\n",
        "  print(\"a is smaller\")\n",
        "elif(a>b):\n",
        "  print(\"b is greater\")\n",
        "else:\n",
        "  if(a<b):\n",
        "    print(\"a is smaller\")\n",
        "  else:\n",
        "    print(\"b is greater\")\n",
        "\n",
        "#Loops\n",
        "numbers=[1,2,3]\n",
        "for i in numbers:\n",
        "  print(i)\n",
        "\n",
        "sum=0\n",
        "for i in range(3):  # i [0,1,2,3) not including 3\n",
        "  sum*=i\n",
        "print(sum)\n",
        "\n",
        "for i in range(3,6):  # i [3,4,5,6) not including 6\n",
        "  sum+=i\n",
        "print(sum)\n",
        "\n",
        "# While Loop\n",
        "i=0\n",
        "while i<3:\n",
        "  print(i)\n",
        "  i+=1\n",
        "\n",
        "#Functions : Reusable block\n",
        "def factorialFunc(num):\n",
        "  factorial=1\n",
        "  for i in range(1,num+1):\n",
        "    factorial*=i\n",
        "  return factorial\n",
        "\n",
        "print(factorialFunc(5))\n"
      ],
      "metadata": {
        "id": "gHJEj353FOcV"
      },
      "id": "gHJEj353FOcV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module-3 Python Libraries\n",
        "- Numpy\n",
        "- Matplotlib\n",
        "- Pandas\n",
        "- Seaborn\n"
      ],
      "metadata": {
        "id": "WBtyzN_5IINI"
      },
      "id": "WBtyzN_5IINI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numpy - Numerical Python\n",
        "- Allows mathematical operations\n",
        "- Faster Operations (large datasets)\n",
        "- Numpy Arrays\n",
        "  - np.array are vector actually not separted by commas\n",
        "  - a.shape // This is used to get dimension of vector\n",
        "  - Number of Dimension print(c.ndim)\n",
        "  - Size No of elements c.size\n",
        "  - len(c) give no of rows len(c[0]) gives no of column\n",
        "  - c.dtype datatype of array\n",
        "  - np.zeros((4,5)) // Zero array\n",
        "  - np.ones((dimenstion x y)) //1 array\n",
        "  - np.full((4,5),10)\n",
        "  - Identityi Matrix np.eye(2)\n",
        "  - Random Matrix np.random.random((3,4))  && np.random.randint(0,10,(3,4),dtype=int)\n",
        "  - List to nparray np.asarray(list1)\n",
        "  - np.arange(10,30,5) Create evenly spaced array with step\n",
        "  - np.linspace(10,30,9) // total 9 numbers\n",
        "\n",
        "- Mathematical Operation\n",
        "  - +-*/ (actual array addition operation element wise dimension need to be same) , incase of list it simply concatenate\n",
        "  - np.divide(a,b) np.add np.subtract np.multiply // same thing\n",
        "  - Since nparray are vectors actually\n",
        "\n",
        "- Array Manipulation\n",
        "  - Transpose np.transpose OR array.T\n",
        "\n",
        "- Reshaping\n",
        "  - b= a.reshape(6,2) if a.size no of elements =12 then b size should be 12 can be 1,12 or 3,4"
      ],
      "metadata": {
        "id": "2W03Gt9YIlBp"
      },
      "id": "2W03Gt9YIlBp"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "9LjE9AiYL4uI"
      },
      "id": "9LjE9AiYL4uI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LIST VS NUMPY - TIME TAKEN"
      ],
      "metadata": {
        "id": "mqimt5_4MgcF"
      },
      "id": "mqimt5_4MgcF"
    },
    {
      "cell_type": "code",
      "source": [
        "from time import process_time\n",
        "\n",
        "#LIST\n",
        "python_list=[i for i in range(100000)]\n",
        "start_time=process_time()\n",
        "\n",
        "python_list=[i+5 for i in python_list ]\n",
        "end_time=process_time()\n",
        "\n",
        "print(\"Python list time taken\", end_time-start_time)\n",
        "\n",
        "#NUMPY Array declare\n",
        "np_array = np.array([i for i in range(100000)])\n",
        "start_time=process_time()\n",
        "\n",
        "# ADDing 5 to all elements in array\n",
        "# np_array += 5 # easy syntax\n",
        "# np_array = np.array([i+5 for i in np_array])\n",
        "for i in range(len(np_array)):\n",
        "  np_array[i]+=5\n",
        "print(np_array)\n",
        "end_time=process_time()\n",
        "\n",
        "print(\"Python Numpy Array time taken\", end_time-start_time)\n"
      ],
      "metadata": {
        "id": "68SrRY07MkVC"
      },
      "id": "68SrRY07MkVC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numpy Arrays"
      ],
      "metadata": {
        "id": "jgNn44oAN75t"
      },
      "id": "jgNn44oAN75t"
    },
    {
      "cell_type": "code",
      "source": [
        "# List Create\n",
        "list1=[1,2,3]\n",
        "type(list1)\n",
        "print(list1)\n",
        "\n",
        "#np array create ->\n",
        "np_array = np.array([1,2,3])\n",
        "type(np_array)\n",
        "print(np_array)\n",
        "# Np array are like vector not separarted by commans"
      ],
      "metadata": {
        "id": "XcxuuWYEN9u4"
      },
      "id": "XcxuuWYEN9u4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating 1D array\n",
        "a= np.array([1,2,3])\n",
        "print(type(a))\n",
        "print(a)\n",
        "a.shape\n",
        "\n",
        "#Creating 2D array\n",
        "b= np.array([(1,2,3),(4,5,6)])\n",
        "b.shape #row and column dimension"
      ],
      "metadata": {
        "id": "Ct3vJ4KDYbfO"
      },
      "id": "Ct3vJ4KDYbfO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datatype defining with np array\n",
        "#default integer hote\n",
        "c= np.array([(1,2),(3,4)],dtype=float)\n",
        "print(c)"
      ],
      "metadata": {
        "id": "Q2sP5GlGZbYh"
      },
      "id": "Q2sP5GlGZbYh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initial Placeholder in numpy arrays\n",
        "# Initial Zeros With Rows and Columns\n",
        "x= np.zeros((4,5))\n",
        "print(x)\n",
        "# Initial Ones With Rows and Columns\n",
        "x= np.ones((4,5))\n",
        "print(x)\n",
        "#Particular Value\n",
        "x= np.full((4,4),10)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "98AEhsX0Zqfq"
      },
      "id": "98AEhsX0Zqfq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Identity Matrix (all diagonal values will be 1 rest 0)\n",
        "# Only n*n hota rows=column\n",
        "a= np.eye(2)\n",
        "print(a)\n",
        "\n",
        "#Random values matrix with dimenssion\n",
        "b= np.random.random((3,4))\n",
        "print(b)\n",
        "\n",
        "#Random matrix integer and within range\n",
        "c= np.random.randint(0,10,(3,4),dtype=int)\n",
        "print(c)\n",
        "\n",
        "#Array with evenly spaced values low high and 9 numbers total\n",
        "d= np.linspace(10,30,9)\n",
        "print(d)\n",
        "\n",
        "#Array with evenly and space -> step jump\n",
        "e= np.arange(10,30,9)\n",
        "print(e)"
      ],
      "metadata": {
        "id": "EPe4dzdtdh8x"
      },
      "id": "EPe4dzdtdh8x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert list/tuple to npArray\n",
        "list1=[1,2,3]\n",
        "tupl1=(1,2,3,4)\n",
        "np_array=np.asarray(list1)\n",
        "print(np_array)"
      ],
      "metadata": {
        "id": "dfLXWIXkfJql"
      },
      "id": "dfLXWIXkfJql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing a numpy array\n",
        "c= np.random.randint(10,90,(5,6))\n",
        "print(c)\n",
        "\n",
        "#Array Dimension\n",
        "c.shape\n",
        "\n",
        "#Number of Dimension\n",
        "print(c.ndim)\n",
        "\n",
        "#Number of elements in array\n",
        "print(c.size)\n",
        "print(len(c[0])) #column numbers\n",
        "\n",
        "#Datatype\n",
        "print(c.dtype)"
      ],
      "metadata": {
        "id": "1SPgDTu4fhyE"
      },
      "id": "1SPgDTu4fhyE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mathematical operations on Numpy Array"
      ],
      "metadata": {
        "id": "_nuScc5MgvIH"
      },
      "id": "_nuScc5MgvIH"
    },
    {
      "cell_type": "code",
      "source": [
        "list1= [1,2,3,4,5]\n",
        "list2=[6,7,8,9,10]\n",
        "# List + concatenate list\n",
        "print(list1+list2) #Element wise adding not happening\n",
        "\n",
        "a= np.asarray(list1)\n",
        "b= np.asarray(list2)\n",
        "#Actual addition\n",
        "print(a+b)\n",
        "\n",
        "a= np.random.randint(10,30,(3,4))\n",
        "b= np.random.randint(10,50,(3,4))\n",
        "print(a/b)\n",
        "#OR\n",
        "print(np.divide(a,b))"
      ],
      "metadata": {
        "id": "bemd3WKvg1Qg"
      },
      "id": "bemd3WKvg1Qg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Array Manipulation on npArray"
      ],
      "metadata": {
        "id": "yHA-sNzgiPuc"
      },
      "id": "yHA-sNzgiPuc"
    },
    {
      "cell_type": "code",
      "source": [
        "#Transpose\n",
        "a= np.random.randint(10,30,(3,4))\n",
        "trans = np.transpose(a)\n",
        "#OR\n",
        "trans2= a.T\n",
        "print(a,a.shape)\n",
        "print(trans,trans.shape)\n",
        "print(trans2,trans2.shape)\n"
      ],
      "metadata": {
        "id": "OtQHQ4x1iSfw"
      },
      "id": "OtQHQ4x1iSfw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reshaping on npArray"
      ],
      "metadata": {
        "id": "CTKaUTMki-6h"
      },
      "id": "CTKaUTMki-6h"
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.random.randint(10,30,(3,4))\n",
        "print(a,a.shape)\n",
        "\n",
        "b= a.reshape(6,2)\n",
        "print(b,b.shape)"
      ],
      "metadata": {
        "id": "sfjLMMGTjEuK"
      },
      "id": "sfjLMMGTjEuK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas - Dataframe\n",
        "- Useful for Data Processing and Analysis\n",
        "- Dataframe is 2d tabular data structure with labeled axes(rows and columns) like excel sheet column name\n",
        "- SKLEARN\n",
        "  - from sklearn.datasets(many datas hai to practice) import load_boston (inbuild datasets hai) sklearn.utils._bunch.Bunch type\n",
        "\n",
        "- Dataframe\n",
        "  - pd.DataFrame, .head() .tail() .info() .isnull().sum() each column null values\n",
        "    - value_counts('magnesium')\n",
        "    - groupby('columnName).mean()\n",
        "    - df['content'] = df['content'].apply(stemming)\n",
        "    - .apply(takes each value and pass this to stemming function)\n",
        "  - pd.read_csv(Give Path to CSV)\n",
        "  - diabetes_df.shape //Dimension\n",
        "  - pd.read_excel(path)\n",
        "  - df.to_csv(\"filename\") wine_df.to_excel(\"wineCSV.\") Exporting to csv and excel\n",
        "  - pd.DataFrame(random_np) // using numpy array to create dataframe\n",
        "  - Statiscial Measures (Each column)\n",
        "    - df.count() mean() std() .min() .max()\n",
        "    - All Statistical in one go df.describe()\n",
        "  - Manipulating Dataframe\n",
        "    - Add Column df['columnname']=1d array or target from dataset {no of values should be same as other columns}\n",
        "  - Locating particular row and column\n",
        "    - .iloc[index] //row print\n",
        "    - .iloc[:,index] //column print : means all rows values\n",
        "    - .iloc[row,col] //particular value\n",
        "    - .iloc[:,-1] #Last column\n",
        "  -  Correlation\n",
        "    - Positive and Negative\n",
        "    - Relation between various columns\n",
        "    - wine_df.corr() # All columns wrt to other column"
      ],
      "metadata": {
        "id": "gBGwEBnnlSc2"
      },
      "id": "gBGwEBnnlSc2"
    },
    {
      "cell_type": "code",
      "source": [
        "# importing\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "iteuwzlBpR-N"
      },
      "id": "iteuwzlBpR-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SKLEARN DATASETS\n",
        "- inbuild datasets"
      ],
      "metadata": {
        "id": "qP0mmiBkpjlQ"
      },
      "id": "qP0mmiBkpjlQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the inbuild datasets\n",
        "# Inbuild data hai\n",
        "from sklearn.datasets import load_wine\n",
        "wine_dataset = load_wine()\n",
        "\n",
        "type(wine_dataset) #sklearn.utils._bunch.Bunch\n",
        "# print(wine_dataset)"
      ],
      "metadata": {
        "id": "5czJl9wMpmTY"
      },
      "id": "5czJl9wMpmTY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pr9Lm-3a--cT"
      },
      "id": "pr9Lm-3a--cT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating Pandas Dataframe"
      ],
      "metadata": {
        "id": "Zt4-1-3ysV8x"
      },
      "id": "Zt4-1-3ysV8x"
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df= pd.DataFrame(wine_dataset.data,columns=wine_dataset.feature_names)\n",
        "# print(wine_df)\n",
        "wine_df.head() #Printing 5 rows\n",
        "# type(wine_df)"
      ],
      "metadata": {
        "id": "7SR0iaf3sUN2"
      },
      "id": "7SR0iaf3sUN2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimenshion of dataframe\n",
        "wine_df.shape"
      ],
      "metadata": {
        "id": "IqeupR6Et80E"
      },
      "id": "IqeupR6Et80E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading CSV File"
      ],
      "metadata": {
        "id": "ms3MqtyCvmVx"
      },
      "id": "ms3MqtyCvmVx"
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing CSV File as a pandas dataframe\n",
        "diabetes_df=pd.read_csv(\"/content/diabetes.csv\")\n",
        "diabetes_df.head()\n",
        "# type(diabetes_df) #pandas.core.frame.DataFrame\n",
        "# diabetes_df.shape"
      ],
      "metadata": {
        "id": "gXmex6Sct-2w"
      },
      "id": "gXmex6Sct-2w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exporting Dataframe to CSV/EXCEL File"
      ],
      "metadata": {
        "id": "j3ou8JLSvpz7"
      },
      "id": "j3ou8JLSvpz7"
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.to_csv(\"wineCSV\")\n",
        "# wine_df.to_excel(\"wineCSV.\")"
      ],
      "metadata": {
        "id": "_b-fnXjJvoVU"
      },
      "id": "_b-fnXjJvoVU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Dataframe with randomNumbers"
      ],
      "metadata": {
        "id": "avz4AU8iA9-y"
      },
      "id": "avz4AU8iA9-y"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "random_np=np.random.rand(20,10)\n",
        "random_np= np.random.randint(0,10,(3,4),dtype=int)\n",
        "random_df = pd.DataFrame(random_np)\n",
        "random_df.head()"
      ],
      "metadata": {
        "id": "OV95AdspBD8T"
      },
      "id": "OV95AdspBD8T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspecting A Dataframe"
      ],
      "metadata": {
        "id": "_D5PMMEuBDYF"
      },
      "id": "_D5PMMEuBDYF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding rows and columns\n",
        "wine_df.shape\n",
        "\n",
        "#First 5 rows in a Dataframe\n",
        "wine_df.head()\n",
        "\n",
        "#Last 5 rows in a Dataframe\n",
        "wine_df.tail()\n",
        "\n",
        "#Information about the Dataframe\n",
        "wine_df.info()"
      ],
      "metadata": {
        "id": "9Ba3Zha9B3li"
      },
      "id": "9Ba3Zha9B3li",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the number of missing values in each column\n",
        "wine_df.isnull().sum()"
      ],
      "metadata": {
        "id": "wJMOMvX-Cc84"
      },
      "id": "wJMOMvX-Cc84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting the values based on a column\n",
        "wine_df.head()\n",
        "\n",
        "\n",
        "wine_df.value_counts('magnesium')"
      ],
      "metadata": {
        "id": "GxCMLoR3Cv0_"
      },
      "id": "GxCMLoR3Cv0_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Group values based on mean\n",
        "wine_df.groupby('magnesium').mean()"
      ],
      "metadata": {
        "id": "lOvS3gqpDW6p"
      },
      "id": "lOvS3gqpDW6p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Statiscial Measures"
      ],
      "metadata": {
        "id": "GwYy84L7DnmA"
      },
      "id": "GwYy84L7DnmA"
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.count()\n",
        "wine_df.mean()\n",
        "wine_df.std()\n",
        "wine_df.min()\n",
        "wine_df.describe() #All in one statiscaly data"
      ],
      "metadata": {
        "id": "UMq1YcWVDqML"
      },
      "id": "UMq1YcWVDqML",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manipulating a Dataframe\n",
        "- add, drop column and row\n",
        "- wine_df.drop(index=0,axis=0) row remove based on index AXIS=0\n",
        "- COLUMN wine_df.drop(columns='RandomAttach',axis=1)remove axis=1\n"
      ],
      "metadata": {
        "id": "ObdXB2GkEbro"
      },
      "id": "ObdXB2GkEbro"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "wine_dataset = load_wine()\n",
        "# print(wine_dataset)\n",
        "wine_df= pd.DataFrame(wine_dataset.data,columns=wine_dataset.feature_names)\n",
        "wine_df.head()\n",
        "\n",
        "# Adding a column in dataframe\n",
        "# wine_dataset has target column till now wine_df uses only feature_name\n",
        "wine_df['Outcome']=wine_dataset.target\n",
        "wine_df.tail()\n",
        "\n",
        "#number of columns length should be same\n",
        "# wine_df.shape (178, 14)\n",
        "temp_np= np.random.randint(10,30,(178,1))\n",
        "# print(temp_np)\n",
        "wine_df['RandomAttach']=temp_np\n",
        "wine_df.tail()"
      ],
      "metadata": {
        "id": "rfjdt8jvEgSr"
      },
      "id": "rfjdt8jvEgSr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing a row\n",
        "wine_df.head()\n",
        "# wine_df.shape\n",
        "wine_df.drop(index=2,axis=0)\n",
        "# wine_df.head()\n",
        "wine_df.drop(columns='RandomAttach',axis=1)"
      ],
      "metadata": {
        "id": "Uns3u6gFGbH6"
      },
      "id": "Uns3u6gFGbH6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Locating a row/column based on index\n"
      ],
      "metadata": {
        "id": "uNrLVFAyHoXr"
      },
      "id": "uNrLVFAyHoXr"
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df_afterRemovingColumn=wine_df.drop(columns='RandomAttach',axis=1)\n",
        "wine_df_afterRemovingColumn.iloc[2]"
      ],
      "metadata": {
        "id": "rYRRc7J6Htco"
      },
      "id": "rYRRc7J6Htco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df_afterRemovingColumn.iloc[:,0] #First column\n",
        "wine_df_afterRemovingColumn.iloc[3,0]\n",
        "wine_df_afterRemovingColumn.iloc[:,-1] #Last column"
      ],
      "metadata": {
        "id": "bJ4SLvzxILG2"
      },
      "id": "bJ4SLvzxILG2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation\n",
        "- Positive and Negative\n",
        "- Relation between various columns"
      ],
      "metadata": {
        "id": "2FWxSE8WNoXI"
      },
      "id": "2FWxSE8WNoXI"
    },
    {
      "cell_type": "code",
      "source": [
        "wine_df.head()\n",
        "wine_df.corr() # All columns wrt to other column\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mJo3wXiSNxzU"
      },
      "id": "mJo3wXiSNxzU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matplotlib - Plots\n",
        " - Plot Figure -> Then Axis define -> Axis Values -> Plot values axes ka title -> Show\n",
        "\n",
        "- Numpy usage\n",
        "  - np.sin(x) cos(x) trignometry x can be array\n",
        "  - x**2 parabola\n",
        "- Plotting Values (X & Y Plotting)\n",
        "  - plt.plot(x,z) plot(x,y,'r+') 'g.' // color and sign\n",
        "  - plt.show()\n",
        "  - plt.xlabel(name) .ylabel(name) .title(PlotName)\n",
        "- Bar Plot\n",
        "  - plt.figure()\n",
        "  - ax = fig.add_axes([0,0,1,1])\n",
        "  - ax.bar(languages,people) 1d 1d array data\n",
        "- Pie Chart\n",
        "  - ax.pie(people,labels=languages,autopct='%1.1f%%') one decimal places\n",
        "- Scatter Plotn # useful in clustering data\n",
        "  - ax.scatter(x,y,color='g')\n",
        "  - x and y 1d values\n",
        "- 3D Scatter Plot\n",
        "  - ax = plt.axes(projection='3d') (projection='3d') #need to mention"
      ],
      "metadata": {
        "id": "LNaVY1F5w0cb"
      },
      "id": "LNaVY1F5w0cb"
    },
    {
      "cell_type": "code",
      "source": [
        "#importing library\n",
        "import matplotlib.pyplot as plt\n",
        "#imporint np for data to plot\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "T2zIDWJ7xAwL"
      },
      "id": "T2zIDWJ7xAwL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= np.linspace(0,10,100) #total 100 values\n",
        "y= np.sin(x) # Create 100 values as vector\n",
        "z= np.cos(x)"
      ],
      "metadata": {
        "id": "VkqfZ2cjyuHC"
      },
      "id": "VkqfZ2cjyuHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plotting the Data (X and Y type)"
      ],
      "metadata": {
        "id": "0J0mf7KBznO0"
      },
      "id": "0J0mf7KBznO0"
    },
    {
      "cell_type": "code",
      "source": [
        "# sine wave x and y\n",
        "plt.plot(x,y)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UueyrzkXzk8-"
      },
      "id": "UueyrzkXzk8-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cosine Wave\n",
        "#Adding Labels in x and y\n",
        "plt.plot(x,z)\n",
        "plt.xlabel(\"Angles\")\n",
        "plt.ylabel(\"Cos Value\")\n",
        "plt.title(\"Trignometry\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "-Bjn0idw0EGA"
      },
      "id": "-Bjn0idw0EGA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PARABOLA\n",
        "x= np.linspace(-10,10,20)\n",
        "y= x**2\n",
        "plt.plot(x,y,'r+')\n",
        "plt.plot(x,y,'g.')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Prp3Xy3V08WA"
      },
      "id": "Prp3Xy3V08WA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging Graphs\n",
        "x= np.linspace(-10,10,500)\n",
        "plt.plot(x,np.sin(x),'r+')\n",
        "plt.plot(x,np.cos(x),'g.')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aXeMBrAe1gbl"
      },
      "id": "aXeMBrAe1gbl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bar Plot"
      ],
      "metadata": {
        "id": "lga8fPZp15kd"
      },
      "id": "lga8fPZp15kd"
    },
    {
      "cell_type": "code",
      "source": [
        "fig= plt.figure() # Empty plot blank\n",
        "ax = fig.add_axes([0,0,1,1]) # Area of plot General value used\n",
        "languages= ['E','A','F','D']\n",
        "people= [100,30,40,50]\n",
        "# language and people same dimension\n",
        "\n",
        "ax.bar(languages,people)\n",
        "plt.xlabel(\"Languages\")\n",
        "plt.ylabel(\"No. of people\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dwED6olF18WD"
      },
      "id": "dwED6olF18WD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pie Chart"
      ],
      "metadata": {
        "id": "gy9PiGan55N9"
      },
      "id": "gy9PiGan55N9"
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = plt.figure()\n",
        "ax = fig1.add_axes([0,0,1,1]) # Area of plot\n",
        "languages= ['E','A','F','D']\n",
        "people= [100,30,40,50]\n",
        "ax.pie(people,labels=languages,autopct='%1.1f%%')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NXmX154p56wX"
      },
      "id": "NXmX154p56wX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scatter Plot"
      ],
      "metadata": {
        "id": "2LF2ETPU80Om"
      },
      "id": "2LF2ETPU80Om"
    },
    {
      "cell_type": "code",
      "source": [
        "# useful in clustering data\n",
        "x= np.linspace(0,10,30)\n",
        "y= np.sin(x)\n",
        "z=np.cos(x)\n",
        "fig2 = plt.figure()\n",
        "ax = fig2.add_axes([0,0,1,1]) # Area of plot Rectangular\n",
        "ax.scatter(x,y,color='g')\n",
        "ax.scatter(x,z,color='b')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "OdCQZJ1u87fo"
      },
      "id": "OdCQZJ1u87fo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3D Scatter Plot"
      ],
      "metadata": {
        "id": "RB9U-MW_9lDF"
      },
      "id": "RB9U-MW_9lDF"
    },
    {
      "cell_type": "code",
      "source": [
        "fig2 = plt.figure()\n",
        "ax = plt.axes(projection='3d') #need to mention\n",
        "z= 20*np.random.random(100)\n",
        "x=np.sin(z)\n",
        "y=np.cos(z)\n",
        "ax.scatter(x,y,z,c=z,cmap='Blues')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9qlZCXTS9nLS"
      },
      "id": "9qlZCXTS9nLS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seaborn - Data Visualization Library\n",
        "- Like Matplot helpful (Sometimes build seaborn plot on top of matplot)\n",
        "- Different Types of plot\n",
        "- Seaborn has some build-in datasets imported as form of `pandas dataframe`\n",
        "  - sns.load_dataset\n",
        "- Commands\n",
        "  - sns.set_theme() // more space and grids\n",
        "  - sns.relplot(data=tips,x='total_bill',y='tip',col='time',hue='smoker',style='smoker',size='size')\n",
        "    - col (differnet plots) hue(same plot differentiate based on hue column)\n",
        "  - sns.scatterplot(x='sepal_length',y='petal_length',hue='species',data=iris)\n",
        "  - sns.countplot(x='class',data=titanic)\n",
        "  - sns.barplot(x='sex',y='survived',hue='class',data=titanic)\n",
        "    - hue(same plot differentiate based on hue column)\n",
        "  - sns.distplot(wine_df['alcohol'])\n",
        "  - sns.heatmap(...) //use with Dataframe\n"
      ],
      "metadata": {
        "id": "b_CzbqGNkFyC"
      },
      "id": "b_CzbqGNkFyC"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "e2saC6mvkWRO"
      },
      "id": "e2saC6mvkWRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build in Seaborn Datasets"
      ],
      "metadata": {
        "id": "A1aP5MGmk4_2"
      },
      "id": "A1aP5MGmk4_2"
    },
    {
      "cell_type": "code",
      "source": [
        "tips= sns.load_dataset(\"tips\")\n",
        "# this tips is pandas dataframe\n",
        "tips.head()"
      ],
      "metadata": {
        "id": "jb2vMZ8jk2Q2"
      },
      "id": "jb2vMZ8jk2Q2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting the theme for plots\n",
        "sns.set_theme()\n",
        "# more spaced and grids"
      ],
      "metadata": {
        "id": "yYry26LinCaC"
      },
      "id": "yYry26LinCaC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Normal Plot"
      ],
      "metadata": {
        "id": "IGvhpTXgQmVH"
      },
      "id": "IGvhpTXgQmVH"
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize data x axis and yaxis with column name + COL (multiple plots for unique value of col)\n",
        "# Data differentiated based on smoker\n",
        "#HUE helps in differentiating us column differnet types\n",
        "sns.relplot(data=tips,x='total_bill',y='tip',col='time',hue='smoker',style='smoker',size='size')\n"
      ],
      "metadata": {
        "id": "7eDhNQ_7lKS6"
      },
      "id": "7eDhNQ_7lKS6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the iris databaset //flower and species\n",
        "iris=sns.load_dataset(\"iris\")\n",
        "iris.head()\n"
      ],
      "metadata": {
        "id": "R3TYWZzRnS3r"
      },
      "id": "R3TYWZzRnS3r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Scatter Plot"
      ],
      "metadata": {
        "id": "3oDfSN_KQkCw"
      },
      "id": "3oDfSN_KQkCw"
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict species of flower based on length and width of sepal and petal\n",
        "\n",
        "#Scatter Plot\n",
        "# sns.scatterplot(x='sepal_length',y='petal_length',hue='species',data=iris)\n",
        "# speices -> differnet colour\n",
        "sns.scatterplot(x='sepal_width',y='petal_width',hue='species',data=iris)\n"
      ],
      "metadata": {
        "id": "9n6a3OpLnpA1"
      },
      "id": "9n6a3OpLnpA1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Titanic Datasets"
      ],
      "metadata": {
        "id": "NETUXiCCQr9z"
      },
      "id": "NETUXiCCQr9z"
    },
    {
      "cell_type": "code",
      "source": [
        "titanic= sns.load_dataset(\"titanic\")\n",
        "titanic.head()\n",
        "# print(titanic.shape)"
      ],
      "metadata": {
        "id": "LaH-UCFkQwT4"
      },
      "id": "LaH-UCFkQwT4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Count Plot"
      ],
      "metadata": {
        "id": "wmFKMybsQ5g7"
      },
      "id": "wmFKMybsQ5g7"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='class',data=titanic)\n",
        "sns.countplot(x='survived',data=titanic)"
      ],
      "metadata": {
        "id": "m5UK3o3xQ7v5"
      },
      "id": "m5UK3o3xQ7v5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Bar chart Plot"
      ],
      "metadata": {
        "id": "6Y0g2rr6RPu0"
      },
      "id": "6Y0g2rr6RPu0"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='sex',y='survived',hue='class',data=titanic)"
      ],
      "metadata": {
        "id": "YJd-6Fb3RPay"
      },
      "id": "YJd-6Fb3RPay",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### House Price Datasets SKLEARN"
      ],
      "metadata": {
        "id": "i0KOS9c6SJAL"
      },
      "id": "i0KOS9c6SJAL"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "wine_dataset = load_wine()\n",
        "\n",
        "wine_df= pd.DataFrame(wine_dataset.data,columns=wine_dataset.feature_names)\n",
        "wine_df[\"target\"]=wine_dataset.target\n",
        "\n",
        "wine_df.tail()"
      ],
      "metadata": {
        "id": "EmFGdgCXSLTS"
      },
      "id": "EmFGdgCXSLTS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Distribution Plot\n",
        "  - Count vs range of all values"
      ],
      "metadata": {
        "id": "xEMNoGWjTYUl"
      },
      "id": "xEMNoGWjTYUl"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(wine_df['alcohol'])"
      ],
      "metadata": {
        "id": "Q5VPjZQcS84c"
      },
      "id": "Q5VPjZQcS84c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### HEAT MAP - Correlation Plot\n",
        "  - Positive one value increase other also increase\n",
        "  - Negative"
      ],
      "metadata": {
        "id": "9emhJfw6T-su"
      },
      "id": "9emhJfw6T-su"
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = wine_df.corr() #by defalt df has this inbuild feature\n",
        "# print(correlation)\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(correlation,cbar=True,square=True,fmt='.1f',annot=True,annot_kws={'size':8},cmap='Blues')"
      ],
      "metadata": {
        "id": "12tOJ3qgULIj"
      },
      "id": "12tOJ3qgULIj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module-4 Data Collection & Pre-Processing\n",
        "\n"
      ],
      "metadata": {
        "id": "Tbm153eSVqcC"
      },
      "id": "Tbm153eSVqcC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Kaggle\n",
        "  - Kaggle.json (generate API Token)\n",
        "  - Make sure join competition to fetch the data\n",
        "  - Kaggle CLI uses ~/.kaggle/ path so your kaggle.json should be copied inside this"
      ],
      "metadata": {
        "id": "d75zQ1D7lrGf"
      },
      "id": "d75zQ1D7lrGf"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "# All ! commands always start with starting path\n",
        "# creating inside root folder\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle\n",
        "!cat ~/.kaggle/kaggle.json\n",
        "#This kaggle folder inside root directory is where pip install works"
      ],
      "metadata": {
        "id": "cx5yISmhlu7P"
      },
      "id": "cx5yISmhlu7P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#API calling use ! as this is system command\n",
        "!kaggle competitions download -c LANL-Earthquake-Prediction"
      ],
      "metadata": {
        "id": "7iegCdk8lqxI"
      },
      "id": "7iegCdk8lqxI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ZIP extract files\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/LANL-Earthquake-Prediction.zip'\n",
        "# Break this inside content folder everything happens there\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "id": "y_Y6pMCZoRXj"
      },
      "id": "y_Y6pMCZoRXj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv('/content/test/seg_00030f.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uWkFhnQ8tegq"
      },
      "id": "uWkFhnQ8tegq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method to Handle Missing Values\n",
        "  - Imputation //using statiscial values and replace those values - mean median and mode\n",
        "  - placement_df['salary'].fillna(placement_df['salary'].median(),inplace=True)\n",
        "  - Dropping //delete rows having missing values only use when you have large dataset\n",
        "  - placement_df_dropping= placement_df_dropping.dropna(how='any')\n"
      ],
      "metadata": {
        "id": "RkDtdljxuG0X"
      },
      "id": "RkDtdljxuG0X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing the libraries"
      ],
      "metadata": {
        "id": "ch7UDpRPxCoJ"
      },
      "id": "ch7UDpRPxCoJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "_coka3QvxEd1"
      },
      "id": "_coka3QvxEd1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the csv file\n",
        "-   /content/Placement_Dataset.csv"
      ],
      "metadata": {
        "id": "Mx1j4mV7xRth"
      },
      "id": "Mx1j4mV7xRth"
    },
    {
      "cell_type": "code",
      "source": [
        "placement_df= pd.read_csv(\"/content/Placement_Dataset.csv\")\n",
        "placement_df.head()\n",
        "placement_df.shape"
      ],
      "metadata": {
        "id": "HxLo9zybxROP"
      },
      "id": "HxLo9zybxROP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding missing values in dataset for all columns\n",
        "- placement_df['salary'].fillna(placement_df['salary'].median(),inplace=True)\n",
        "// filling missing values"
      ],
      "metadata": {
        "id": "4FIGAl9fxvUB"
      },
      "id": "4FIGAl9fxvUB"
    },
    {
      "cell_type": "code",
      "source": [
        "placement_df.isnull().sum()"
      ],
      "metadata": {
        "id": "H1Gf3GDnxbmC"
      },
      "id": "H1Gf3GDnxbmC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Central Tendencies\n",
        "- mean median and mode\n",
        "- replace null values in column\n",
        "- RULES: SKEWDISTRIBUTION distplot -> Outlier hai value mein achanak kuch values kafi higher **`Cant use MEAN` Use median or mode"
      ],
      "metadata": {
        "id": "c4JDMajByE5S"
      },
      "id": "c4JDMajByE5S"
    },
    {
      "cell_type": "code",
      "source": [
        "placement_df[\"salary\"].describe()\n",
        "\n",
        "# Analyze the distribution of data in the salary\n",
        "# fix,ax= plt.subplots(figsize=(8,8))\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.distplot(placement_df['salary'])\n",
        "\n",
        "# Outliers hai very less count for higher salary\n",
        "# MEAN WIll be wrong\n",
        "\n"
      ],
      "metadata": {
        "id": "Vl6nFvLYx2KU"
      },
      "id": "Vl6nFvLYx2KU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Replacing missing values with median/mode value"
      ],
      "metadata": {
        "id": "gEyN6grX1hs_"
      },
      "id": "gEyN6grX1hs_"
    },
    {
      "cell_type": "code",
      "source": [
        "placement_df['salary'].fillna(placement_df['salary'].median(),inplace=True)\n",
        "#Check missing values\n",
        "placement_df.isnull().sum()"
      ],
      "metadata": {
        "id": "oYdZagmI02ce"
      },
      "id": "oYdZagmI02ce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dropping Values which are null"
      ],
      "metadata": {
        "id": "sf76G9_D2ahY"
      },
      "id": "sf76G9_D2ahY"
    },
    {
      "cell_type": "code",
      "source": [
        "placement_df_dropping = pd.read_csv(\"/content/Placement_Dataset.csv\")\n",
        "placement_df_dropping.shape\n",
        "placement_df_dropping.isnull().sum()"
      ],
      "metadata": {
        "id": "YN0DaqSx2dx-"
      },
      "id": "YN0DaqSx2dx-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "placement_df_dropping= placement_df_dropping.dropna(how='any')\n",
        "placement_df_dropping.shape"
      ],
      "metadata": {
        "id": "awzhw5GH3rY5"
      },
      "id": "awzhw5GH3rY5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Standardization\n",
        "- The process of standarization the data to common format and comman range\n",
        "- one column -100,100 other -1000 to +1000 range Want to make all column in common range\n",
        "- SKLEARN - datasets, transform function, train and test spliting data\n",
        "  - Spliting data { x_train, x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=3) }\n",
        "- StandardScaler doesnt change nature of data only data point are changes accorigin to formula z= (x-u)/s where s is standard deviation and x is data point and u is mean\n",
        "  - scaler.fit(x_train)\n",
        "  - x_train_standarized= scaler.transform(x_train)\n",
        "\n",
        "  - .fit() calculated meand and std\n",
        "  - .transform() applies formulat to x using fit value\n",
        "\n",
        "- x_train to fit data and use its mean and std to transform both (x train and test data)"
      ],
      "metadata": {
        "id": "mKjgi_tI5KAb"
      },
      "id": "mKjgi_tI5KAb"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "BSfJZ3Zc5M-d"
      },
      "id": "BSfJZ3Zc5M-d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "dataset= sklearn.datasets.load_breast_cancer()\n",
        "type(dataset)\n",
        "# print(dataset)\n",
        "breast_df= pd.DataFrame(data=dataset.data,columns=dataset.feature_names)\n",
        "# breast_df['target']=dataset.target\n",
        "breast_df.tail()\n",
        "\n",
        "# All columns are in different range\n",
        "# Data Standard karenge before feeding to ml model\n",
        "breast_df.shape\n"
      ],
      "metadata": {
        "id": "TnnLcOuO6Ykx"
      },
      "id": "TnnLcOuO6Ykx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining input and iouput\n",
        "x= breast_df\n",
        "print(x)\n",
        "y= dataset.target\n",
        "print(y)"
      ],
      "metadata": {
        "id": "D0YOc0At7xsZ"
      },
      "id": "D0YOc0At7xsZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spliting the data into training data and test data"
      ],
      "metadata": {
        "id": "PoY_4NRt9CG5"
      },
      "id": "PoY_4NRt9CG5"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=3)\n",
        "print(x.shape,x_train.shape,x_test.shape)"
      ],
      "metadata": {
        "id": "y_6rF--X8M4d"
      },
      "id": "y_6rF--X8M4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standardize the data\n",
        "  - Use standard deviation of the data to see how much it vary from mean value"
      ],
      "metadata": {
        "id": "Q6C5xomJ9FxD"
      },
      "id": "Q6C5xomJ9FxD"
    },
    {
      "cell_type": "code",
      "source": [
        "# It treats the entire 569 × 30 = 17,070 values as a single long list, then calculates the standard deviation of that list.\n",
        "print(dataset.data.std())\n",
        "# OR\n",
        "np.std(dataset.data)\n",
        "# np.mean(dataset.data)\n",
        "# Normal standard deviation\n",
        "# x= np.asarray([1,2,3])\n",
        "# np.std(x)"
      ],
      "metadata": {
        "id": "zJxSguC29Hrs"
      },
      "id": "zJxSguC29Hrs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "# doesnt change nature of data only data point are changes accorigin to formula z= (x-u)/s where s is standard deviation and x is data point and u is mean\n",
        "\n",
        "# Xtrain\n",
        "scaler.fit(x_train)\n",
        "x_train_standarized= scaler.transform(x_train)\n",
        "# print(x_train_standarized)\n",
        "# Now value is in range\n",
        "\n",
        "#OR\n",
        "\n",
        "# x_train_standarized=scaler.fit_transform(x_train)\n",
        "print(x_train_standarized)\n",
        "np.std(x_train_standarized)\n",
        "\n",
        "# Now test data based on scaler fit of x train data\n",
        "\n",
        "# Transforming based on x_train(mean and std) as fit with x_train\n",
        "x_test_standarised = scaler.transform(x_test)\n",
        "np.std(x_test_standarised)\n",
        "\n"
      ],
      "metadata": {
        "id": "sAvkP0LhAzwc"
      },
      "id": "sAvkP0LhAzwc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encoding (SKLEARN)\n",
        "  - Converting the labels into numeric form\n",
        "  - used in classification model 0 or 1 type\n",
        "  - breast_df['diagnosis'].value_counts() // count of differnet types withing a column\n",
        "  - label_encode.fit_transform(breast_df['diagnosis'])"
      ],
      "metadata": {
        "id": "Dmv9e2M1NhiY"
      },
      "id": "Dmv9e2M1NhiY"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Kdx7-YQaPFc6"
      },
      "id": "Kdx7-YQaPFc6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Breast Cancer Data\n",
        "breast_df= pd.read_csv(\"/content/breast_cancert.csv\")\n",
        "breast_df.tail()"
      ],
      "metadata": {
        "id": "vEmB4XeOQFbb"
      },
      "id": "vEmB4XeOQFbb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change lables M AND B in diagnois column into numeric form\n",
        "\n",
        "#Finding the count of differnet labels inside column diagnoisis\n",
        "breast_df['diagnosis'].value_counts()"
      ],
      "metadata": {
        "id": "dqxNHAQ_QWw1"
      },
      "id": "dqxNHAQ_QWw1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the LabelEncoder funtion\n",
        "label_encode= LabelEncoder()\n",
        "# LABELS either 0 or 1 based on column with labels different\n",
        "labels=label_encode.fit_transform(breast_df['diagnosis'])"
      ],
      "metadata": {
        "id": "fOq6-3eOQomH"
      },
      "id": "fOq6-3eOQomH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Appending the labels to data frame\n",
        "\n",
        "# labels alphabetical wise B=0 M=1 aise dega numbers\n",
        "breast_df[\"target_diagnosis\"]=labels\n",
        "# By default, .drop() returns a new DataFrame.\n",
        "# breast_df.drop(columns=['diagnosis'],inplace=True)\n",
        "breast_df.tail()\n",
        "\n",
        "breast_df[\"target_diagnosis\"].value_counts()"
      ],
      "metadata": {
        "id": "UiUU-QEgRRyr"
      },
      "id": "UiUU-QEgRRyr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IRIS DATABASE 3 Labels\n",
        "iris_df=pd.read_csv(\"/content/iris_data.csv\")\n",
        "iris_df['Species'].value_counts()\n",
        "label_encode= LabelEncoder()\n",
        "labels=label_encode.fit_transform(iris_df['Species'])\n",
        "iris_df['Target_Species']=labels\n",
        "iris_df['Target_Species'].value_counts()"
      ],
      "metadata": {
        "id": "5ox5iO8ASHra"
      },
      "id": "5ox5iO8ASHra",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split\n",
        "- Data\n",
        "- Data Preprocessing\n",
        "  - Standarization (Standard Scaler from sklearn.preprocessing)\n",
        "- Data Analysis\n",
        "  - matplot seaborn\n",
        "- Train Test Split\n",
        "  - x_train, x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=3)\n",
        "- ML Model and Algo\n",
        "  - skelearn import svm (support vector matrix)\n",
        "- Evaluation"
      ],
      "metadata": {
        "id": "5UET-y_ZeZ-J"
      },
      "id": "5UET-y_ZeZ-J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handle Imbalanced Data\n",
        "- Outcome postive = 1000 rows negative 100 rows\n",
        "- Then break random data from postiive into 100 rows and merge 100+ and 100- as net data for proper balance\n",
        "- credit_df['Class'].value_counts()\n",
        "- legit = credit_df[credit_df.Class == 0]\n",
        "- Under-Sampling\n",
        "  - Build a sample of data with equal distribution\n",
        "  - legit_sample= legit.sample(264)\n",
        "  - new_data = pd.concat([legit_sample,fraud_sample],axis=0)\n",
        "  - axis=0 means firstly legit data then fraud data"
      ],
      "metadata": {
        "id": "j893Xn3hfK0H"
      },
      "id": "j893Xn3hfK0H"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0Gw7UkeqfZXW"
      },
      "id": "0Gw7UkeqfZXW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credit_df= pd.read_csv(\"/content/credit_data.csv\");\n",
        "credit_df.head()"
      ],
      "metadata": {
        "id": "TPmTAVigflkF"
      },
      "id": "TPmTAVigflkF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credit_df['Class'].value_counts()\n",
        "# Class\n",
        "# 0.0\t138458\n",
        "# 1.0\t264\n",
        "# Highlt imbalanced data"
      ],
      "metadata": {
        "id": "WFkomtTbftfZ"
      },
      "id": "WFkomtTbftfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 separate legit and fraud data\n",
        "legit = credit_df[credit_df.Class == 0]\n",
        "fraud = credit_df[credit_df.Class == 1]\n",
        "legit.head()\n",
        "print(legit.shape , fraud.shape)"
      ],
      "metadata": {
        "id": "LMy6oIzmf3qL"
      },
      "id": "LMy6oIzmf3qL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0Sc6HqklgDOv"
      },
      "id": "0Sc6HqklgDOv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Under-Sampling\n",
        "\n",
        "# Randomly bread legit into equal number as of fraud\n",
        "# (138458, 31) (264, 31)\n",
        "\n",
        "legit_sample= legit.sample(264)\n",
        "fraud_sample= fraud\n",
        "print(legit_sample.shape , fraud_sample.shape)\n",
        "\n",
        "#Concatenate\n",
        "new_data = pd.concat([legit_sample,fraud_sample],axis=0)\n",
        "new_data['Class'].value_counts()"
      ],
      "metadata": {
        "id": "_N6tYmcggK8A"
      },
      "id": "_N6tYmcggK8A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gbdo9Be8gm5h"
      },
      "id": "gbdo9Be8gm5h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Extraction of Text TfIDF vectorizer\n",
        "“How important is a word in a particular document relative to the whole dataset?”\n",
        "Mapping from textual data to real valued vector is called feature extraction\n",
        "- Bag Of Words (BOW) - number of unique words\n",
        "- Term Frequency- Inverse Document Frequency(TF-IDF)\n",
        "  - TF * IDF\n",
        "  - To count the number of times each word appears in a document\n",
        "- Document is a string like arr[0]\n",
        "- TF- number of times term t appears in document/ no of terms in the document\n",
        "- IDF log(N/n) N is no of documents and n is the no of documents a term t appeared in\n",
        "- Maths hai bas see chatGPT\n",
        "- Words unique importance nikalna frequence basis pe aisa kuc\n",
        "\n",
        "\n",
        "---\n",
        "- Use sklearn.feature_extraction.text import TfIdfVectorizer\n",
        "- vectorizer= TfidfVectorizer()\n",
        "- vectorizer.fit(document) #Calculation karna\n",
        "- X=vectorizer.transform(document)\n",
        "- print(vectorizer.get_feature_names_out()) // Get unique words\n",
        "- print(vectorizer.vocabulary_) // indexes of each words\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sHgePLhqhYUC"
      },
      "id": "sHgePLhqhYUC"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n"
      ],
      "metadata": {
        "id": "Fj4_tgUKihMy"
      },
      "id": "Fj4_tgUKihMy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document=np.array([\"First first first\",\"second first second\",\"third second first\"])\n",
        "vectorizer= TfidfVectorizer()\n",
        "vectorizer.fit(document) #Calculation karna\n",
        "X=vectorizer.transform(document)\n",
        "print(X)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "id": "P4QqMFeBij3Z"
      },
      "id": "P4QqMFeBij3Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MgV5RyZJahvN"
      },
      "id": "MgV5RyZJahvN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numerical Dataset PreProcessing\n",
        "- using diabetes.csv for practising\n",
        "- Whenever pandas df passes through functions like scaler train converts to numpy array"
      ],
      "metadata": {
        "id": "X3Nj81JTakff"
      },
      "id": "X3Nj81JTakff"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "RjoFt3D-a2s0"
      },
      "id": "RjoFt3D-a2s0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df=pd.read_csv(\"/content/diabetes.csv\")\n",
        "diabetes_df.head()\n",
        "diabetes_df['Outcome'].value_counts()\n",
        "diabetes_df.shape"
      ],
      "metadata": {
        "id": "v-C9Q7OIa5QJ"
      },
      "id": "v-C9Q7OIa5QJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Collection and Preprocessing"
      ],
      "metadata": {
        "id": "IaIiZUHEbSHy"
      },
      "id": "IaIiZUHEbSHy"
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df.describe()"
      ],
      "metadata": {
        "id": "CyVRc889bRmb"
      },
      "id": "CyVRc889bRmb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Separate x and y input and output values"
      ],
      "metadata": {
        "id": "rOVgYwlvbir9"
      },
      "id": "rOVgYwlvbir9"
    },
    {
      "cell_type": "code",
      "source": [
        "x = diabetes_df.drop(columns=\"Outcome\",axis=1)\n",
        "# dropping a column then axis =1\n",
        "y= diabetes_df['Outcome']\n",
        "type(x)\n",
        "# 0 - Non-Diabetic\n",
        "# 1- Diabetic"
      ],
      "metadata": {
        "id": "XZSIMN6ibm6N"
      },
      "id": "XZSIMN6ibm6N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Standarization to make machine understand data better\n",
        "- Some people first standarize data and then split in train and testing\n",
        "- Here author follows the same\n",
        "- Some people first split and then standarize"
      ],
      "metadata": {
        "id": "llj41RMmcUVf"
      },
      "id": "llj41RMmcUVf"
    },
    {
      "cell_type": "code",
      "source": [
        "scaler= StandardScaler()\n",
        "standarised_dataX= scaler.fit_transform(x)\n",
        "print(standarised_dataX,type(standarised_dataX))"
      ],
      "metadata": {
        "id": "cihBcZG4cUB8"
      },
      "id": "cihBcZG4cUB8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and Testing Data"
      ],
      "metadata": {
        "id": "rOrzk6UOcOMi"
      },
      "id": "rOrzk6UOcOMi"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test,y_train,y_test=train_test_split(standarised_dataX,y,test_size=0.2,random_state=3)\n",
        "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
        "print(type(x_train))\n"
      ],
      "metadata": {
        "id": "llu2Y77QcMZp"
      },
      "id": "llu2Y77QcMZp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Dataset PreProcessing\n",
        "- re library for regular expression\n",
        "- nltk\n",
        "  - corpus is collection of words\n",
        "  - natural language tool kit -> text processing\n",
        "  - Stopwords -> english words that appear frequently in english sentences\n",
        "    - for data preprocessing need to remove them as they dont convey much information\n",
        "  - PorterStemmer - For Stemming\n",
        "- Stemming: is the process of reducing a word to its root word\n",
        "  - ex. enjoy enjoyinh enjoyable can be replaced with enjoy\n",
        "  - re.sub('[^a-zA-Z]') using regular expression\n",
        "- Text data to numerical data\n",
        "  - use Tfidf Vectorizer\n",
        "\n",
        "Steps:\n",
        "- Select input fields merge columns\n",
        "- Text -> stemming stopwords convert\n",
        "- Text -> Numerical Vectorizer\n",
        "  - vectorizer uses only string not list when fit and transform\n",
        "- now everything in numericals\n",
        "- Train and Split"
      ],
      "metadata": {
        "id": "57IbcktCeE-2"
      },
      "id": "57IbcktCeE-2"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk #entire library importing\n",
        "from nltk.corpus import stopwords\n",
        "#corpus is collection of words\n",
        "#natural language tool kit -> text processing\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "GYsLSIf-gmYA"
      },
      "id": "GYsLSIf-gmYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Downloading stopwords"
      ],
      "metadata": {
        "id": "6gVTaYkvi0tp"
      },
      "id": "6gVTaYkvi0tp"
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "# Printing the stopwords\n",
        "print(stopwords.words('swedish'))"
      ],
      "metadata": {
        "id": "NQMN0jnNh-gq"
      },
      "id": "NQMN0jnNh-gq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Data preprocessing"
      ],
      "metadata": {
        "id": "eJFu136Wi4sW"
      },
      "id": "eJFu136Wi4sW"
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/train.csv\n",
        "df = pd.read_csv(\"/content/train.csv\")\n",
        "df.head()\n",
        "# Label 0 - Real 1- Fake\n",
        "# Train model which news are fake and which are real\n",
        "df.shape"
      ],
      "metadata": {
        "id": "03BnKvlpgp25"
      },
      "id": "03BnKvlpgp25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Label 0 - Real\n",
        "##### Label 1- Fake"
      ],
      "metadata": {
        "id": "AITOss5IjEXM"
      },
      "id": "AITOss5IjEXM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Checking for missing values"
      ],
      "metadata": {
        "id": "PiVXPXfajNp_"
      },
      "id": "PiVXPXfajNp_"
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "1B0FhLPajP9a"
      },
      "id": "1B0FhLPajP9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Handle missing value\n",
        "- Text replace with 'nan' string\n",
        "- In case of data we generally replace using mean median and mode"
      ],
      "metadata": {
        "id": "g-v7-T9QjYpH"
      },
      "id": "g-v7-T9QjYpH"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna('')\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "YNK7_K-AjhDr"
      },
      "id": "YNK7_K-AjhDr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Merging two feature to treat as input\n",
        "- author and title -> gives ouput label"
      ],
      "metadata": {
        "id": "pTgb0wWGjzC8"
      },
      "id": "pTgb0wWGjzC8"
    },
    {
      "cell_type": "code",
      "source": [
        "df['content']= df['author'] + ' '+ df['title']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "e6y5J939juAF"
      },
      "id": "e6y5J939juAF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Separating target and features\n",
        "- feature content\n",
        "- traget label"
      ],
      "metadata": {
        "id": "UXo0_ZbYkKMh"
      },
      "id": "UXo0_ZbYkKMh"
    },
    {
      "cell_type": "code",
      "source": [
        "x= df['content']\n",
        "y=df['label']\n",
        "x.head()"
      ],
      "metadata": {
        "id": "b3mn7p0VkZvW"
      },
      "id": "b3mn7p0VkZvW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Stemming\n",
        "- Process of reducinf a word to its root word\n",
        "- Use PorterStemmer\n",
        "- re.sub('[^a-zA-Z] (string se only take a-z and A-Z ^means not)"
      ],
      "metadata": {
        "id": "Q7O7mSR_lFfS"
      },
      "id": "Q7O7mSR_lFfS"
    },
    {
      "cell_type": "code",
      "source": [
        "port_stem= PorterStemmer()"
      ],
      "metadata": {
        "id": "JgQRz4YGlMVD"
      },
      "id": "JgQRz4YGlMVD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(content):\n",
        "  stemmed_content= re.sub('[^a-zA-Z]',' ',content) # replcaing char to ' '\n",
        "  stemmed_content= stemmed_content.lower()\n",
        "  stemmed_content=stemmed_content.split() #User ' ' to split words\n",
        "  # print(stemmed_content)\n",
        "  stemmed_content= [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  # Array list to string\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "  return stemmed_content\n",
        "# Content - >\" string , : aise\"\n",
        "# remove characters convert to lower\n",
        "# Split the words ' ' separted\n",
        "# ignoring words present in stopwords english\n",
        "# port stem root word for each word mein convert\n"
      ],
      "metadata": {
        "id": "gAlQvTQFlRBl"
      },
      "id": "gAlQvTQFlRBl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for x data use the function\n",
        "df['content'] = df['content'].apply(stemming)\n",
        "# Pass each row value apply\n",
        "print(df['content'])"
      ],
      "metadata": {
        "id": "_-k_dT3GnEl8"
      },
      "id": "_-k_dT3GnEl8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Taking x and y data as numpy arrays"
      ],
      "metadata": {
        "id": "HzXAPN-xpCA1"
      },
      "id": "HzXAPN-xpCA1"
    },
    {
      "cell_type": "code",
      "source": [
        "x= df['content'].values\n",
        "y=df['label'].values"
      ],
      "metadata": {
        "id": "niWGtCj9pBZS"
      },
      "id": "niWGtCj9pBZS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Now Text To feature Vector\n",
        "- Text data to numerical data"
      ],
      "metadata": {
        "id": "riH-kWPbpfAE"
      },
      "id": "riH-kWPbpfAE"
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer= TfidfVectorizer()\n",
        "x= vectorizer.fit_transform(x)\n",
        "# vectorizer uses only string so x [\"string\",\"string\"] type not [[\"\"],[\"\"]]"
      ],
      "metadata": {
        "id": "WwmOKK7dp_RF"
      },
      "id": "WwmOKK7dp_RF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "id": "6hIiWEOJrKnt"
      },
      "id": "6hIiWEOJrKnt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module-5 Mathematics\n",
        "\n"
      ],
      "metadata": {
        "id": "qzmLy9T1un8q"
      },
      "id": "qzmLy9T1un8q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Operation\n",
        "- plt.quiver(Cordinates inital-base final, scale, color )\n",
        "- plt.xlim Rangle of x and y ylim\n",
        "- vector1 + - *\n",
        "- Dot Product- np.dot(a,b) -> Gives number\n",
        "- Cross Product-  np.cross(a,b) -> Gives result in vector form\n",
        "\n",
        "### Vectors are Numpy Arrays origin and final\n",
        "- Need four point 0,0,4,5 vector is defined"
      ],
      "metadata": {
        "id": "R_ExrZLnwIPw"
      },
      "id": "R_ExrZLnwIPw"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "CxQeXA7JwJkX"
      },
      "id": "CxQeXA7JwJkX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting theme of seaborn\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "GswP9ghcwWWH"
      },
      "id": "GswP9ghcwWWH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting a vector"
      ],
      "metadata": {
        "id": "zLOZIZQdwahA"
      },
      "id": "zLOZIZQdwahA"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.quiver(0,0,4,5)\n",
        "# Cordinates inital final\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "prY66tZGwZ7_"
      },
      "id": "prY66tZGwZ7_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.quiver(-1,0,4,5,scale_units='xy',angles='xy',scale=1)\n",
        "# Rangle of x and y\n",
        "plt.xlim(-8,8)\n",
        "plt.ylim(-8,8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ITrr5Q_w7Kl"
      },
      "id": "6ITrr5Q_w7Kl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing color and multiple vectors in single plot\n",
        "plt.quiver(-1,0,4,5,scale_units='xy',angles='xy',scale=1,color='b')\n",
        "plt.quiver(-1,0,4,9,scale_units='xy',angles='xy',scale=1,color='r')\n",
        "# Rangle of x and y\n",
        "plt.xlim(-8,9)\n",
        "plt.ylim(-8,9)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aVJ99KPOxnzU"
      },
      "id": "aVJ99KPOxnzU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Addition | Subtraction | Multiply By Scalar of vectors"
      ],
      "metadata": {
        "id": "BLWA4H2lx0NC"
      },
      "id": "BLWA4H2lx0NC"
    },
    {
      "cell_type": "code",
      "source": [
        "vector1=np.asarray([0,0,2,3])\n",
        "vector2=np.asarray([0,0,-2,3])\n",
        "\n",
        "sum = vector1 + vector2\n",
        "print(sum)\n",
        "\n",
        "sub = vector1 - vector2\n",
        "print(sub)\n",
        "\n",
        "scalerMultiple = 2*vector1\n",
        "print(scalerMultiple)\n"
      ],
      "metadata": {
        "id": "OHNszrp6x-iv"
      },
      "id": "OHNszrp6x-iv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dot and Cross product of Vectors\n",
        " - Projection of one vector on other\n",
        " - Formula projection = (a.v/||v||2 ) v vector\n",
        "  - np.sqrt(np.sum(b**2)) b1 square + b2 square aise hoga saare elements ka sum"
      ],
      "metadata": {
        "id": "XDvRR5Fey74w"
      },
      "id": "XDvRR5Fey74w"
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.array([2,3,5])\n",
        "b= np.array([4,4,5])\n",
        "\n",
        "dot = np.dot(a,b)\n",
        "print(dot)\n",
        "\n",
        "cross= np.cross(a,b)\n",
        "print(cross)\n",
        "\n",
        "# Projection of a vector on b\n",
        "#  Formula proja = (a.v/||v||2 ) v vector\n",
        "\n",
        "\n",
        "magnitude_of_b= np.sqrt(np.sum(b**2))\n",
        "proj_a_on_b = (np.dot(a,b)/magnitude_of_b**2)*b\n",
        "print(proj_a_on_b)\n"
      ],
      "metadata": {
        "id": "BvaV-sz7y9za"
      },
      "id": "BvaV-sz7y9za",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix\n",
        "- Creating matrix using numpy\n",
        "  - simple array of array np.array\n",
        "  - matrix_1.shape dimension of matrix\n",
        "  - Random Matrix\n",
        "    - np.random.rand(3,4)\n",
        "    - np.random.randint(100,size=(3,4))\n",
        "  - One Values matrix\n",
        "    - np.ones((2,3))\n",
        "    - np.ones((2,3),dtype=int)\n",
        "  - Zero Value matrix\n",
        "    - np.zeros((2,3),dtype=int)\n",
        "  - Identiy Matrix\n",
        "    - np.eye(3,4)\n",
        "  - Transpose of Matrix\n",
        "    - np.transpose(a)\n",
        "\n",
        "- Operation in Matrix\n",
        "  - Addition|Subtact {+ - or np.add(a,b) np.subtract}\n",
        "  - Multiple m*n and need other to n*p final m*p create\n",
        "    - Scalar OR element wise np.multiply(a,b) {a*b}\n",
        "    - Actual m*n wala need np.dot(a,b)"
      ],
      "metadata": {
        "id": "pKEcviLU2WVw"
      },
      "id": "pKEcviLU2WVw"
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_1 = np.array([[1,2],[3,4]])\n",
        "print(matrix_1)\n",
        "print(matrix_1.shape)"
      ],
      "metadata": {
        "id": "pEihhghX2X1T"
      },
      "id": "pEihhghX2X1T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random matrix\n",
        "random_matrix= np.random.rand(3,4)\n",
        "print(random_matrix)\n",
        "\n",
        "random_matrix_integer = np.random.randint(100,size=(3,4))\n",
        "print(random_matrix_integer)"
      ],
      "metadata": {
        "id": "U1sEgs3s2t_S"
      },
      "id": "U1sEgs3s2t_S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_3= np.ones((2,3),dtype=int)\n",
        "print(matrix_3)"
      ],
      "metadata": {
        "id": "8L6niIv13Gyf"
      },
      "id": "8L6niIv13Gyf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero Matrix\n",
        "matrix_3= np.zeros((2,3),dtype=int)\n",
        "print(matrix_3)"
      ],
      "metadata": {
        "id": "OH6IoELd3XWn"
      },
      "id": "OH6IoELd3XWn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identity Matrix\n",
        "matrix_3= np.eye(3,4)\n",
        "print(matrix_3)"
      ],
      "metadata": {
        "id": "wRYBX4W33g17"
      },
      "id": "wRYBX4W33g17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose of Matrix\n",
        "a= np.random.randint(100,size=(3,4))\n",
        "print(a)\n",
        "transpose= np.transpose(a)\n",
        "print(transpose)\n"
      ],
      "metadata": {
        "id": "2n7reRkd3gwc"
      },
      "id": "2n7reRkd3gwc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Operations"
      ],
      "metadata": {
        "id": "45k6apM550Cc"
      },
      "id": "45k6apM550Cc"
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.random.randint(100,size=(3,4))\n",
        "b= np.random.randint(100,size=(3,4))\n",
        "\n",
        "addition = a+b\n",
        "addition = np.add(a,b)\n",
        "print(addition)\n",
        "\n",
        "subtract = a-b\n",
        "subtraction = np.subtract(a,b)\n",
        "print(subtraction)"
      ],
      "metadata": {
        "id": "fiE2msi1514Y"
      },
      "id": "fiE2msi1514Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multiply\n",
        "  - m*n and need other to n*p final m*p create"
      ],
      "metadata": {
        "id": "v3jWVmEX6q1N"
      },
      "id": "v3jWVmEX6q1N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Scalar or element wise"
      ],
      "metadata": {
        "id": "Q-DOZ1Nf7h1s"
      },
      "id": "Q-DOZ1Nf7h1s"
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.random.randint(100,size=(3,4))\n",
        "b= a= np.random.randint(100,size=(4,5))\n",
        "mul= np.multiply(a,b)\n",
        "print(mul , mul.shape)\n",
        "mul = a*b\n",
        "print(mul , mul.shape)\n"
      ],
      "metadata": {
        "id": "Yas4A9Rv61-8"
      },
      "id": "Yas4A9Rv61-8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multiply 2 matrices"
      ],
      "metadata": {
        "id": "LrLjwyqe7kTP"
      },
      "id": "LrLjwyqe7kTP"
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.random.randint(100,size=(3,4))\n",
        "b= np.random.randint(100,size=(4,5))\n",
        "mul= np.dot(a,b)\n",
        "print(mul , mul.shape)\n"
      ],
      "metadata": {
        "id": "d0LN0gIE7m-H"
      },
      "id": "d0LN0gIE7m-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module-7 ML Models Algo\n",
        "\n"
      ],
      "metadata": {
        "id": "X0x-ohgp-P-w"
      },
      "id": "X0x-ohgp-P-w"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression\n",
        "  - y= mx+c\n",
        "  - Gradient descent\n",
        "    - m = m - L*dm\n",
        "    - c = c- L*dc\n",
        "    - dm = -2/n SUM(xi(yi-yipred))\n",
        "    - dc =-2/n SUM(yi-yipred)\n",
        "    - Derived in collab notes\n",
        "  - L is learning rate minimize loss function"
      ],
      "metadata": {
        "id": "90OeqRXU-TJu"
      },
      "id": "90OeqRXU-TJu"
    },
    {
      "cell_type": "code",
      "source": [
        "# importint numpy library\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2sfWBQbH_1Fn"
      },
      "id": "2sfWBQbH_1Fn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating Own Linear Regression Model**\n",
        "  - Import Linear Regression as a file and use in other code\n",
        "    - Create .py file and paste code in it\n",
        "    - Paste in Sample_data folder\n",
        "    - use import File.py and use that funnction and classes\n",
        "    - model = file.Linear_Regression() // object of that class  "
      ],
      "metadata": {
        "id": "G_JV_Kjd_45I"
      },
      "id": "G_JV_Kjd_45I"
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_Regression:\n",
        "\n",
        "  # Initiate the parameters (Learning rate and iterations number)\n",
        "  def __init__(self,learning_rate,no_of_iterations):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.no_of_iterations = no_of_iterations\n",
        "\n",
        "  # X and Y columns arrays\n",
        "  def fit(self,X,Y):\n",
        "\n",
        "    # number of training examples(data points) & number of features (X kitne hai x1,x2...)\n",
        "    self.m,self.n= X.shape # no of rows and column\n",
        "\n",
        "    #initiating the weight and bias\n",
        "    self.w = np.zeros(self.n) #number of columns feature kitne x1 x2 x3...\n",
        "    self.b = 0\n",
        "\n",
        "    # X = m*n W= n*1 Ypredict =m*1 output ek saath dot product\n",
        "\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "    #Implementing Gradient Descent\n",
        "    for i in range(self.no_of_iterations):\n",
        "      self.update_weights()\n",
        "\n",
        "\n",
        "\n",
        "  def update_weights(self):\n",
        "    Y_prediction = self.predict(self.X)\n",
        "\n",
        "    #Calculate the gradient\n",
        "    # SUM xi(yi - ypred) xi m*n (30,1) xTranspose n*m(1,30) y->m*1(30,1) dot-> gives sum(1,1)\n",
        "    dw = -(2*(np.transpose(self.X).dot(self.Y- Y_prediction)))/(self.m)\n",
        "    db = -2 * np.sum(self.Y - Y_prediction)/self.m\n",
        "\n",
        "    self.w = self.w - self.learning_rate*dw\n",
        "    self.b = self.b - self.learning_rate*db\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Plugging to formula Ypredi = WX+B\n",
        "    # X = m*n W= n*1 Ypredict =m*1 output ek saath dot product\n",
        "    print(X.shape,self.w.shape)\n",
        "    return np.dot(X,self.w) + self.b\n"
      ],
      "metadata": {
        "id": "A604DzxBATpX"
      },
      "id": "A604DzxBATpX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Linear_Regression(0.01,100)\n",
        "# Model object instance uses by SELF"
      ],
      "metadata": {
        "id": "VNHzL4CnA7cx"
      },
      "id": "VNHzL4CnA7cx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset salary_data\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "2JZtSVsuYlq3"
      },
      "id": "2JZtSVsuYlq3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_df = pd.read_csv(\"/content/salary_data.csv\")\n",
        "salary_df.head()\n",
        "\n",
        "# X = salary_df.YearsExperience;\n",
        "# Y= salary_df.Salary\n",
        "# X.head()\n",
        "# Y.head()\n",
        "# print(X.shape)\n",
        "\n",
        "# X_npArray= np.asarray(X).reshape(-1, 1)\n",
        "# Y_npArray = np.asarray(Y)\n",
        "# print(Y_npArray.shape)\n",
        "\n",
        "\n",
        "X= salary_df.iloc[:,:-1].values  #removing last column # [1:10:1] 1 to 10th column and stepsize1\n",
        "Y= salary_df.iloc[:,1].values\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "h2qxc4tsYx7c"
      },
      "id": "h2qxc4tsYx7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=3)\n",
        "print(Y_npArray.shape,x_train.shape,x_test.shape)"
      ],
      "metadata": {
        "id": "2XPuIXkOZiDZ"
      },
      "id": "2XPuIXkOZiDZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train)\n",
        "print(\"weight = \",model.w[0])\n",
        "print(\"bias = \",model.b)"
      ],
      "metadata": {
        "id": "_SwuUUCfaLN-"
      },
      "id": "_SwuUUCfaLN-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(x_test)\n",
        "print(y_predicted)"
      ],
      "metadata": {
        "id": "TvVpNrTGchx9"
      },
      "id": "TvVpNrTGchx9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualing the predicted and actual values"
      ],
      "metadata": {
        "id": "mHsW3-oHhEQA"
      },
      "id": "mHsW3-oHhEQA"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "GBbiPXGuhD_3"
      },
      "id": "GBbiPXGuhD_3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x_test,y_test,color='r')\n",
        "plt.plot(x_test,y_predicted,color='b')\n",
        "plt.xlabel(\"Years Experience\")\n",
        "plt.ylabel(\"Salary\")\n",
        "plt.title(\"LinearRegression\")\n",
        "#plot continous\n",
        "# scatter dot"
      ],
      "metadata": {
        "id": "J7MuVfGyhKXr"
      },
      "id": "J7MuVfGyhKXr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "- Multiple Columns can use Data Standarization\n",
        "- y_hat = 1/(1+e-z) z= wx+b\n",
        "- y_pred will be in 0 and 1 not y_hat but use same formula\n",
        "- w= w-Ldw\n",
        "- b= b-Ldb\n",
        "- Derivation on notes -> using loss function and cost function\n",
        "  - dw= 1*(ŷ-y).X / m\n",
        "    - this need dot as dw itself is a array\n",
        "  - db= 1*(ŷ-y)/m\n",
        "    - db need np.sum since this is a constant\n",
        "  - m is size of rows\n",
        "- np.where(Y_Predicted > 0.5 , 1,0)\n",
        "  - all elements in array pe match and return np array"
      ],
      "metadata": {
        "id": "o_PoAL5X_c4j"
      },
      "id": "o_PoAL5X_c4j"
    },
    {
      "cell_type": "code",
      "source": [
        "# importint numpy library\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ekpPi0L3_7vk"
      },
      "id": "ekpPi0L3_7vk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Logistic_Regression:\n",
        "\n",
        "  # Initiate the parameters (Learning rate and iterations number)\n",
        "  def __init__(self,learning_rate,no_of_iterations):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.no_of_iterations = no_of_iterations\n",
        "\n",
        "  # X and Y columns arrays\n",
        "  def fit(self,X,Y):\n",
        "\n",
        "    # number of training examples(data points) & number of features (X kitne hai x1,x2...)\n",
        "    self.m,self.n= X.shape # no of rows and column\n",
        "\n",
        "    #initiating the weight and bias\n",
        "    self.w = np.zeros(self.n) #number of columns feature kitne x1 x2 x3...\n",
        "    self.b = 0\n",
        "\n",
        "    # X = m*n W= n*1 Ypredict =m*1 output ek saath dot product\n",
        "\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "    #Implementing Gradient Descent\n",
        "    for i in range(self.no_of_iterations):\n",
        "      self.update_weights()\n",
        "\n",
        "\n",
        "\n",
        "  def update_weights(self):\n",
        "    #  This is formula based not exactly 0 and 1\n",
        "    Y_hat = 1/(1+np.exp(-(np.dot(self.X,self.w)+self.b))) # wx+b\n",
        "\n",
        "    #Calculate the gradient\n",
        "    # SUM xi(yi - ypred) xi m*n (30,1) xTranspose n*m(1,30) y->m*1(30,1) dot-> gives sum(1,1)\n",
        "    dw = (np.transpose(self.X).dot(Y_hat-self.Y))*(1/self.m)\n",
        "    db = np.sum(Y_hat-self.Y)*(1/self.m)\n",
        "\n",
        "    self.w = self.w - self.learning_rate*dw\n",
        "    self.b = self.b - self.learning_rate*db\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Plugging to formula Ypredi = WX+B\n",
        "    # X = m*n W= n*1 Ypredict =m*1 output ek saath dot product\n",
        "    # Y_Predicted can be 0 and 1 only\n",
        "    Y_Predicted = 1/(1+np.exp(-(np.dot(X,self.w)+self.b)))\n",
        "    Y_Predicted = np.where(Y_Predicted > 0.5 , 1,0)\n",
        "    return Y_Predicted\n"
      ],
      "metadata": {
        "id": "s4i1JR_8AA8Z"
      },
      "id": "s4i1JR_8AA8Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Logistic Regression"
      ],
      "metadata": {
        "id": "9M3WZlrNENIS"
      },
      "id": "9M3WZlrNENIS"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Logistic_Regression(0.01,100)\n",
        "# Model object instance uses by SELF"
      ],
      "metadata": {
        "id": "fvA4FSgREwqy"
      },
      "id": "fvA4FSgREwqy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset salary_data\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "zjP1STCREQHa"
      },
      "id": "zjP1STCREQHa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df = pd.read_csv(\"/content/diabetes.csv\")\n",
        "diabetes_df.head()\n",
        "X= diabetes_df.iloc[:,:-1].values  #removing last column # [1:10:1] 1 to 10th column and stepsize1\n",
        "Y= diabetes_df['Outcome']\n",
        "print(X.shape,Y.shape)"
      ],
      "metadata": {
        "id": "1O0Y0PRMES_G"
      },
      "id": "1O0Y0PRMES_G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Standarization"
      ],
      "metadata": {
        "id": "iNbRRhq8Gd8j"
      },
      "id": "iNbRRhq8Gd8j"
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "standarised_dataX= scaler.transform(X)\n",
        "print(standarised_dataX)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "cb04ETUKGxVa"
      },
      "id": "cb04ETUKGxVa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test,y_train,y_test=train_test_split(standarised_dataX,Y,test_size=0.2,random_state=3)\n",
        "print(x_train.shape,x_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "FxVq2KTgEkLz"
      },
      "id": "FxVq2KTgEkLz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train)\n",
        "print(\"weight = \",model.w)\n",
        "print(\"bias = \",model.b)"
      ],
      "metadata": {
        "id": "JN1lPCq0E6-p"
      },
      "id": "JN1lPCq0E6-p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(x_test)\n",
        "print(y_predicted,y_predicted.shape)"
      ],
      "metadata": {
        "id": "pRbp4K5UFDFY"
      },
      "id": "pRbp4K5UFDFY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy Score\n",
        "  - Logistic Classifier use Accuracy Score = correct_prediction/totat_number"
      ],
      "metadata": {
        "id": "86hYXde6HS-z"
      },
      "id": "86hYXde6HS-z"
    },
    {
      "cell_type": "code",
      "source": [
        "test_score_accuracy = accuracy_score(y_test,y_predicted)\n",
        "print(test_score_accuracy)"
      ],
      "metadata": {
        "id": "5mNK4NLZHcZa"
      },
      "id": "5mNK4NLZHcZa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM Algo\n",
        "- eq of hyperplane = y= wx-b into two groups\n",
        "- w = w - L*dw\n",
        "- b = b- L*db\n",
        "- lambda_parameter use here 0.01 type\n",
        "- if(yi(wxi-b) >=1 dj/dq= 2*lambda*w dj/db=0\n",
        "- if(yi(wxi-b) < 1 dj/dq= 2*lambda*w - yixi dj/db=yi\n",
        "\n",
        "### SVM output +1 or -1 convert output\n",
        "- np.where(self.Y <=0, -1,1)\n",
        "- predicted_label = np.sign(output) // negative and positive to class +1 and -1"
      ],
      "metadata": {
        "id": "pRvckaDKkaMF"
      },
      "id": "pRvckaDKkaMF"
    },
    {
      "cell_type": "code",
      "source": [
        "# importint numpy library\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XE-C4azSlPBn"
      },
      "id": "XE-C4azSlPBn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM_Classifier:\n",
        "\n",
        "  # Initiate the parameters (Learning rate and iterations number)\n",
        "  def __init__(self,learning_rate,no_of_iterations,lambda_parameter):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.no_of_iterations = no_of_iterations\n",
        "    self.lambda_parameter = lambda_parameter\n",
        "  # X and Y columns arrays\n",
        "  def fit(self,X,Y):\n",
        "\n",
        "    # number of training examples(data points) & number of features (X kitne hai x1,x2...)\n",
        "    self.m,self.n= X.shape # no of rows and column\n",
        "\n",
        "    #initiating the weight and bias\n",
        "    self.w = np.zeros(self.n) #number of columns feature kitne x1 x2 x3...\n",
        "    self.b = 0\n",
        "\n",
        "    # X = m*n W= n*1 Ypredict =m*1 output ek saath dot product\n",
        "\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "    #Implementing Gradient Descent\n",
        "    for i in range(self.no_of_iterations):\n",
        "      self.update_weights()\n",
        "\n",
        "\n",
        "\n",
        "  def update_weights(self):\n",
        "    # label encoding (actual output ko change according to svm class)\n",
        "    y_label = np.where(self.Y <=0, -1,1)\n",
        "    for index, x_i in enumerate(self.X):\n",
        "      # y_i*(wx_i+b) >1 or<1\n",
        "      # y_i is ylabel data se direct\n",
        "      condition = y_label[index]*(np.dot(x_i,self.w)-self.b)>=1\n",
        "      if(condition == True):\n",
        "        dw = 2*self.lambda_parameter * self.w\n",
        "        db = 0\n",
        "      else:\n",
        "        dw = 2*self.lambda_parameter * self.w - np.dot(x_i,y_label[index])\n",
        "        db = y_label[index]\n",
        "\n",
        "      self.w = self.w - self.learning_rate*dw\n",
        "      self.b = self.b - self.learning_rate*db\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Output y= wx-b\n",
        "    output = np.dot(X,self.w) - self.b\n",
        "    # output can be anything positive and negative\n",
        "    predicted_label = np.sign(output)\n",
        "\n",
        "    #Our original data either 0 and 1\n",
        "    y_hat = np.where(predicted_label<=-1,0,1)\n",
        "    return y_hat\n",
        "\n"
      ],
      "metadata": {
        "id": "m2UNf3LOlWmA"
      },
      "id": "m2UNf3LOlWmA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Diabetes Dataset"
      ],
      "metadata": {
        "id": "9vSWpPKklnUn"
      },
      "id": "9vSWpPKklnUn"
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVM_Classifier(0.01,1000,0.01)\n",
        "# Model object instance uses by SELF"
      ],
      "metadata": {
        "id": "gBe6DccelhnP"
      },
      "id": "gBe6DccelhnP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset salary_data\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "wt8zDy3HlkSF"
      },
      "id": "wt8zDy3HlkSF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df = pd.read_csv(\"/content/diabetes.csv\")\n",
        "diabetes_df.head()\n",
        "X= diabetes_df.iloc[:,:-1].values  #removing last column # [1:10:1] 1 to 10th column and stepsize1\n",
        "Y= diabetes_df['Outcome']\n",
        "print(X.shape,Y.shape)"
      ],
      "metadata": {
        "id": "jlQg-SkSlqfd"
      },
      "id": "jlQg-SkSlqfd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Standardization"
      ],
      "metadata": {
        "id": "1SKpsKGApm7J"
      },
      "id": "1SKpsKGApm7J"
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "standarised_dataX= scaler.transform(X)\n",
        "print(standarised_dataX)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "l7RvfLbkltFX"
      },
      "id": "l7RvfLbkltFX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test,y_train,y_test=train_test_split(standarised_dataX,Y,test_size=0.2,random_state=3)\n",
        "print(x_train.shape,x_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "qcLZeRBSlxf4"
      },
      "id": "qcLZeRBSlxf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train)\n",
        "print(\"weight = \",model.w)\n",
        "print(\"bias = \",model.b)"
      ],
      "metadata": {
        "id": "pUL08EnflzWJ"
      },
      "id": "pUL08EnflzWJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(x_test)\n",
        "print(y_predicted,y_predicted.shape)"
      ],
      "metadata": {
        "id": "N756OMVdl08_"
      },
      "id": "N756OMVdl08_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score_accuracy = accuracy_score(y_test,y_predicted)\n",
        "print(test_score_accuracy)"
      ],
      "metadata": {
        "id": "yTnef6e7l2i1"
      },
      "id": "yTnef6e7l2i1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Y_output accuracy\n",
        "y_predicted = model.predict(x_train)\n",
        "print(accuracy_score(y_train,y_predicted))"
      ],
      "metadata": {
        "id": "IpoNGdUbAFbC"
      },
      "id": "IpoNGdUbAFbC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lasso Regression\n",
        "- Regression Data\n",
        "- y= wx+b\n",
        "- if(wj>0)\n",
        "  - dj/dw = -2/m[[Sum(0,m) xj(yi - y_hat)] +lamda]\n",
        "- if(wj< 0)\n",
        "  - dj/dw = -2/m[[Sum(0,m) xj(yi - y_hat)] -lamda]\n",
        "- dj/db = -2/m[[Sum(0,m)(yi - y_hat)]\n",
        "- w= w - L*dw\n"
      ],
      "metadata": {
        "id": "wfNZ5hdSZdrz"
      },
      "id": "wfNZ5hdSZdrz"
    },
    {
      "cell_type": "code",
      "source": [
        "# importint numpy library\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "EoVpkaK6aG6X"
      },
      "id": "EoVpkaK6aG6X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lasso_Regression:\n",
        "\n",
        "  # Initiate the parameters (Learning rate and iterations number)\n",
        "  def __init__(self,learning_rate,no_of_iterations,lambda_parameter):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.no_of_iterations = no_of_iterations\n",
        "    self.lambda_parameter = lambda_parameter\n",
        "  # X and Y columns arrays\n",
        "  def fit(self,X,Y):\n",
        "\n",
        "    # number of training examples(data points) & number of features (X kitne hai x1,x2...)\n",
        "    self.m,self.n= X.shape # no of rows and column\n",
        "\n",
        "    #initiating the weight and bias\n",
        "    self.w = np.zeros(self.n) #number of columns feature kitne x1 x2 x3...\n",
        "    self.b = 0\n",
        "\n",
        "    # X = m*n W= n*1 Ypredict =m*1 output ek saath dot product\n",
        "\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "    #Implementing Gradient Descent\n",
        "    for i in range(self.no_of_iterations):\n",
        "      self.update_weights()\n",
        "\n",
        "\n",
        "\n",
        "  def update_weights(self):\n",
        "      y_prediction = self.predict(self.X)\n",
        "\n",
        "      #dw and db xj is complete column\n",
        "      dw = np.zeroes(self.n)\n",
        "      for i in range(self.n):\n",
        "        if self.w[i] > 0:\n",
        "          dw[i]=(-(2*self.X[:,i]).dot(self.Y-y_prediction) + self.lambda_parameter)/self.m\n",
        "        else :\n",
        "          dw[i]=(-(2*self.X[:,i]).dot(self.Y-y_prediction) - self.lambda_parameter)/self.m\n",
        "\n",
        "      db = -2*np.sum(self.Y-y_prediction)/self.m\n",
        "      self.w = self.w - self.learning_rate*dw\n",
        "      self.b = self.b - self.learning_rate*db\n",
        "\n",
        "  def predict(self, X):\n",
        "      return np.dot(X,self.w) + self.b\n",
        "\n"
      ],
      "metadata": {
        "id": "EK3k_5MCaIwF"
      },
      "id": "EK3k_5MCaIwF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Lasso_Regression(0.01,1000,0.01)"
      ],
      "metadata": {
        "id": "0PXIyvlwj1VY"
      },
      "id": "0PXIyvlwj1VY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN Algo\n",
        "- Used for both classification and regression"
      ],
      "metadata": {
        "id": "mVxHUzNwmP76"
      },
      "id": "mVxHUzNwmP76"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Euclidean and Manhattan distance"
      ],
      "metadata": {
        "id": "c3LGttYvmceQ"
      },
      "id": "c3LGttYvmceQ"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "p1 = (1,2)\n",
        "p2= (3,4)\n",
        "p1= np.asarray(p1)\n",
        "p2= np.asarray(p2)\n",
        "\n",
        "def get_euclidean_distance(p1,p2):\n",
        "  dist=0\n",
        "  for i in range(len(p1)):\n",
        "    dist = dist + (p1[i] - p2[i])**2\n",
        "\n",
        "  e_dis = np.sqrt(dist)\n",
        "  return e_dis\n",
        "\n",
        "def get_manhattan_distance(p1,p2):\n",
        "  dist=0\n",
        "  for i in range(len(p1)):\n",
        "    dist = dist + abs(p1[i] - p2[i])\n",
        "\n",
        "  return dist\n",
        "\n",
        "\n",
        "print(get_manhattan_distance(p1,p2))"
      ],
      "metadata": {
        "id": "MEy9sGU1mf5y"
      },
      "id": "MEy9sGU1mf5y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN Algo\n",
        "- use statistics\n",
        "  - mean medida mode of array\n",
        "-predicted_class = statistics.mode(label)\n",
        "    # mode because classifier model bana rahe\n",
        "- use one two point system\n",
        "- x_train means all points including outcome\n",
        "- x_train [(a,b,c,target),(),()]\n",
        "- final distance calculate using all points"
      ],
      "metadata": {
        "id": "_Ko7iYQC8WbV"
      },
      "id": "_Ko7iYQC8WbV"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statistics"
      ],
      "metadata": {
        "id": "BkWXIUxL8Xm1"
      },
      "id": "BkWXIUxL8Xm1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K-Nearest Classfier\n",
        "- Can only predict for one data point at a time\n",
        "- called lazy model since no need to fit jo data points hai unse predict karn\n",
        "-  So x and y are combined but while calulating distance use only X\n",
        "  - that why distance len-1 tak gaye hai\n",
        "  - but predict time last index use as that is y"
      ],
      "metadata": {
        "id": "D8qTq6bAGVyi"
      },
      "id": "D8qTq6bAGVyi"
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN_Classifier():\n",
        "  def __init__(self,distance_metric):\n",
        "    # distance_metric either euclidean or manhattan\n",
        "    self.distance_metric=distance_metric\n",
        "\n",
        "  def get_distance_metrics(self,training_data_point,test_data_point):\n",
        "    # code for\n",
        "    if(self.distance_metric=='euclidean'):\n",
        "      return self.get_euclidean_distance(training_data_point,test_data_point)\n",
        "\n",
        "    elif(self.distance_metric=='manhatten'):\n",
        "      return self.get_manhattan_distance(training_data_point,test_data_point)\n",
        "\n",
        "\n",
        "  def nearest_neighbors(self,x_train,test_data,k):\n",
        "    # train_data is single point x_train is array of points\n",
        "    # k nearest distance points\n",
        "    distance_list = []\n",
        "    for training_data in x_train:\n",
        "      distance = self.get_distance_metrics(training_data,test_data)\n",
        "      distance_list.append((training_data, distance))\n",
        "      # [(training_data1, distance1), (training_data2, distance2), ...]\n",
        "    #  sort by the second item (distance) in each tuple:\n",
        "    distance_list.sort(key=lambda x: x[1])\n",
        "    # Filter least k points in distance list array\n",
        "    neighbors= []\n",
        "    for j in range(k):\n",
        "      neighbors.append(distance_list[j][0])\n",
        "    return neighbors\n",
        "\n",
        "  def predict(self,x_train,test_data,k):\n",
        "    neighbors = self.nearest_neighbors(x_train,test_data,k)\n",
        "    label = []\n",
        "    for data in neighbors:\n",
        "      label.append(data[-1])\n",
        "      # data[-1] represents the last element of the list data\n",
        "    predicted_class = statistics.mode(label)\n",
        "    # mode because classifier model bana rahe\n",
        "    return predicted_class\n",
        "  def get_euclidean_distance(self,p1,p2):\n",
        "    dist=0\n",
        "    # since last index is y ouput toh only x wala le rahe\n",
        "    for i in range(len(p1)-1):\n",
        "      dist = dist + (p1[i] - p2[i])**2\n",
        "\n",
        "    e_dis = np.sqrt(dist)\n",
        "    return e_dis\n",
        "\n",
        "  def get_manhattan_distance(self,p1,p2):\n",
        "    dist=0\n",
        "    for i in range(len(p1)-1):\n",
        "      dist = dist + abs(p1[i] - p2[i])\n",
        "\n",
        "    return dist"
      ],
      "metadata": {
        "id": "2kKq9NROGaEg"
      },
      "id": "2kKq9NROGaEg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Diabetes Dataset"
      ],
      "metadata": {
        "id": "onWFY4xRLvn-"
      },
      "id": "onWFY4xRLvn-"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "I5ER0gDULx0E"
      },
      "id": "I5ER0gDULx0E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df= pd.read_csv(\"/content/diabetes.csv\")\n",
        "diabetes_df.head()"
      ],
      "metadata": {
        "id": "F5r_MIzBL4Jg"
      },
      "id": "F5r_MIzBL4Jg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df.shape"
      ],
      "metadata": {
        "id": "RtNKBT6vM5Pf"
      },
      "id": "RtNKBT6vM5Pf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = diabetes_df.drop(columns='Outcome',axis=1)\n",
        "y = diabetes_df['Outcome']\n",
        "x= np.asarray(x)\n",
        "y= np.asarray(y)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "OiKgDHZMM65v"
      },
      "id": "OiKgDHZMM65v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NOTE:\n",
        "stratify=y does:\n",
        "It ensures that the class distribution (labels in y) is preserved in both the training and test sets.\n",
        "\n",
        "In other words:\n",
        "\n",
        "If your original dataset y has 30% class A and 70% class B,\n",
        "\n",
        "Then both y_train and y_test will also have approximately 30% A and 70% B."
      ],
      "metadata": {
        "id": "Fnd92_KUNjwl"
      },
      "id": "Fnd92_KUNjwl"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2,stratify=y)"
      ],
      "metadata": {
        "id": "aq7WdycVNROp"
      },
      "id": "aq7WdycVNROp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "id": "FHSyIjshNl0a"
      },
      "id": "FHSyIjshNl0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine x_train and y_train column-wise\n",
        "x_train_with_y = np.column_stack((x_train, y_train))\n",
        "print(x_train_with_y.shape)\n",
        "print(x_train_with_y)\n",
        "\n",
        "# So x and y are combined but while calulating distance use only X\n",
        "# print 9th column\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "6PzPI2aQOXm3"
      },
      "id": "6PzPI2aQOXm3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model KNN Classifier"
      ],
      "metadata": {
        "id": "kFdD8A-vPXK1"
      },
      "id": "kFdD8A-vPXK1"
    },
    {
      "cell_type": "code",
      "source": [
        "classifer = KNN_Classifier(distance_metric= 'euclidean')"
      ],
      "metadata": {
        "id": "NHqGedIxPY96"
      },
      "id": "NHqGedIxPY96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction= classifer.predict(x_train_with_y,x_test[3],k=5)\n",
        "print(prediction)\n",
        "print(x_test[3])\n",
        "print(y_test[3])"
      ],
      "metadata": {
        "id": "RnTwbn3UPulj"
      },
      "id": "RnTwbn3UPulj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "print(y_test.shape)\n",
        "for i in range (y_test.shape[0]):\n",
        "  y_pred.append(classifer.predict(x_train_with_y,x_test[i],k=5))\n",
        "\n",
        "print(y_pred[3])"
      ],
      "metadata": {
        "id": "IAm6VqUqRrYR"
      },
      "id": "IAm6VqUqRrYR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy score"
      ],
      "metadata": {
        "id": "lLlLwPD-Sk3-"
      },
      "id": "lLlLwPD-Sk3-"
    },
    {
      "cell_type": "code",
      "source": [
        "accuracyScore = accuracy_score(y_pred,y_test)\n",
        "print(accuracyScore)"
      ],
      "metadata": {
        "id": "BsSSGo8mSoMw"
      },
      "id": "BsSSGo8mSoMw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module-8 Model Deployment | Selection | Accuracy | Confusion Matrix"
      ],
      "metadata": {
        "id": "UdPWZCU7P8xV"
      },
      "id": "UdPWZCU7P8xV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML Model Deployment\n",
        "- Anaconda and Streamlit\n",
        "  - donwload anaconda with default setting\n",
        "    - create environment python 3.8\n",
        "    - withing these environment install anything\n",
        "      - open terminal\n",
        "      - pip install streamlit\n",
        "      - streamlit open server port listening\n",
        "      - pip install sklearn numpy matplotlib etc.....\n",
        "      - pip install pickle-mixin (for model loading)\n",
        "      - spyder code editor in python save this py file\n",
        "      - terminal open and run streamlit (py file created using spyder)\n",
        "  - install streamlit through anaconda\n",
        "    - python version 3.6-3.9\n",
        "    - Streamlit gives a port server\n",
        "  - Deploy using streamlit\n",
        "    - trained model deploy and server listen webpage\n",
        "    - import pickle | pickle.dump(model, filename.sav, wb)\n",
        "    - load model = pickle.load(open(filename),sb)\n",
        "  - Use Streamlit to write code in python and use this model loaded\n",
        "    - create function the code which you use in predictive system while making projects\n",
        "    - def main (): Can create basic UI asking inputs from user\n",
        "    - and then call main function which is predicting\n",
        "- Pickle\n",
        "  - model as .sav format save file trained hai jo data pe"
      ],
      "metadata": {
        "id": "TaJ6n3_KVu7E"
      },
      "id": "TaJ6n3_KVu7E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold Cross Validation\n",
        "- use cross_val_score from sklearn.model_selection\n",
        "- Alternative to Train Test Split Hota hai"
      ],
      "metadata": {
        "id": "aLBlk2TvWFjr"
      },
      "id": "aLBlk2TvWFjr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the Dependencies"
      ],
      "metadata": {
        "id": "bFJFyzowbp1A"
      },
      "id": "bFJFyzowbp1A"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "WgewH1wLWHcQ"
      },
      "id": "WgewH1wLWHcQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "9wCjERuy7oMZ"
      },
      "id": "9wCjERuy7oMZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Collection and Processing"
      ],
      "metadata": {
        "id": "NEPER65f66Tb"
      },
      "id": "NEPER65f66Tb"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the csv data to a Pandas DataFrame\n",
        "heart_data = pd.read_csv('/content/heart_disease_data.csv')\n",
        "# print first 5 rows of the dataset\n",
        "heart_data.head()"
      ],
      "metadata": {
        "id": "zaktZZhx4uI7"
      },
      "id": "zaktZZhx4uI7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of rows and columns in the dataset\n",
        "heart_data.shape\n",
        "# checking for missing values\n",
        "heart_data.isnull().sum()\n",
        "# checking the distribution of Target Variable\n",
        "heart_data['target'].value_counts()"
      ],
      "metadata": {
        "id": "Wds7Pd8y7B1L"
      },
      "id": "Wds7Pd8y7B1L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 --> Defective Heart\n",
        "\n",
        "0 --> Healthy Heart"
      ],
      "metadata": {
        "id": "2a_vllnR7HCf"
      },
      "id": "2a_vllnR7HCf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Features and Target"
      ],
      "metadata": {
        "id": "Zocc1uWH7NhY"
      },
      "id": "Zocc1uWH7NhY"
    },
    {
      "cell_type": "code",
      "source": [
        "X = heart_data.drop(columns='target', axis=1)\n",
        "Y = heart_data['target']"
      ],
      "metadata": {
        "id": "5Yg1iic_7N-g"
      },
      "id": "5Yg1iic_7N-g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "yLCxjMY37Pvi"
      },
      "id": "yLCxjMY37Pvi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "id": "K2_xRg-B7SIr"
      },
      "id": "K2_xRg-B7SIr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Train Test Split** Method-1 Compare Different Models"
      ],
      "metadata": {
        "id": "mmz8WcYp7VUS"
      },
      "id": "mmz8WcYp7VUS"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=3)"
      ],
      "metadata": {
        "id": "XlARGmj_7WTT"
      },
      "id": "XlARGmj_7WTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "kibhIjD47c0O"
      },
      "id": "kibhIjD47c0O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the performance of the models"
      ],
      "metadata": {
        "id": "iUCMKsmK7e67"
      },
      "id": "iUCMKsmK7e67"
    },
    {
      "cell_type": "code",
      "source": [
        "# list of models\n",
        "models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier()]"
      ],
      "metadata": {
        "id": "lS-srbH57fX1"
      },
      "id": "lS-srbH57fX1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models_train_test():\n",
        "\n",
        "  for model in models:\n",
        "\n",
        "    # training the model\n",
        "    model.fit(X_train, Y_train)\n",
        "\n",
        "    # evaluating the model\n",
        "    test_data_prediction = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(Y_test, test_data_prediction)\n",
        "\n",
        "    print('Accuracy score of the ', model, ' = ', accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "8htMbMNv7dPj"
      },
      "id": "8htMbMNv7dPj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models_train_test()"
      ],
      "metadata": {
        "id": "ConEUqjY7ugS"
      },
      "id": "ConEUqjY7ugS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Cross Validation** Method-2\n",
        "- By default decide khud se Test and Train Data\n",
        "- If CV=5 KFOLD is used and dataset divide into 5 chunks\n",
        "- CV_Score of each iteration milega\n",
        "\n",
        "- Syntax -  cross_val_score(SVC(kernel='linear'), X, Y, cv=5)"
      ],
      "metadata": {
        "id": "Wf783hX19fwN"
      },
      "id": "Wf783hX19fwN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "cpRlz36P9vfe"
      },
      "id": "cpRlz36P9vfe"
    },
    {
      "cell_type": "code",
      "source": [
        "cv_score_lr = cross_val_score(LogisticRegression(max_iter=1000), X, Y, cv=5)\n",
        "\n",
        "print(cv_score_lr)\n",
        "\n",
        "mean_accuracy_lr = sum(cv_score_lr)/len(cv_score_lr)\n",
        "\n",
        "mean_accuracy_lr = mean_accuracy_lr*100\n",
        "\n",
        "mean_accuracy_lr = round(mean_accuracy_lr, 2)\n",
        "\n",
        "print(mean_accuracy_lr)"
      ],
      "metadata": {
        "id": "fIkZCHab746J"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fIkZCHab746J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Classifier"
      ],
      "metadata": {
        "id": "RA7W2es0AFD3"
      },
      "id": "RA7W2es0AFD3"
    },
    {
      "cell_type": "code",
      "source": [
        "cv_score_svc = cross_val_score(SVC(kernel='linear'), X, Y, cv=5)\n",
        "\n",
        "print(cv_score_svc)\n",
        "\n",
        "mean_accuracy_svc = sum(cv_score_svc)/len(cv_score_svc)\n",
        "\n",
        "mean_accuracy_svc = mean_accuracy_svc*100\n",
        "\n",
        "mean_accuracy_svc = round(mean_accuracy_svc, 2)\n",
        "\n",
        "print(mean_accuracy_svc)"
      ],
      "metadata": {
        "id": "nNCZfeSe-0oZ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nNCZfeSe-0oZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Function to compare the models"
      ],
      "metadata": {
        "id": "PlM83YyPApq_"
      },
      "id": "PlM83YyPApq_"
    },
    {
      "cell_type": "code",
      "source": [
        "# list of models\n",
        "models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier()]"
      ],
      "metadata": {
        "id": "uyAZczwYAT3f"
      },
      "execution_count": null,
      "outputs": [],
      "id": "uyAZczwYAT3f"
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models_cross_validation():\n",
        "\n",
        "  for model in models:\n",
        "\n",
        "    cv_score = cross_val_score(model, X,Y, cv=5)\n",
        "\n",
        "    mean_accuracy = sum(cv_score)/len(cv_score)\n",
        "\n",
        "    mean_accuracy = mean_accuracy*100\n",
        "\n",
        "    mean_accuracy = round(mean_accuracy, 2)\n",
        "\n",
        "    print('Cross Validation accuracies for ', model, '=  ', cv_score)\n",
        "    print('Accuracy % of the ', model, mean_accuracy)\n",
        "    print('----------------------------------------------')\n"
      ],
      "metadata": {
        "id": "AWfa55OKAygv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "AWfa55OKAygv"
    },
    {
      "cell_type": "code",
      "source": [
        "compare_models_cross_validation()"
      ],
      "metadata": {
        "id": "QaCp6U_cBvVM"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QaCp6U_cBvVM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameter Tuning:**\n",
        "\n",
        "\n",
        "1.   GridSearchCV\n",
        "2.   RandomizedSearchCV\n",
        "- need to tune parameters like deciding no_of_iteration, SVC(linear,sigmoid, etc)\n",
        "-Example SVC -> which model linear poly\n",
        "- and cost C=1,5,10\n",
        "\n"
      ],
      "metadata": {
        "id": "D5IrrV6uJMh8"
      },
      "id": "D5IrrV6uJMh8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eFgKfedIpHm"
      },
      "outputs": [],
      "source": [
        "# importing the dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "id": "6eFgKfedIpHm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be working on the breast cancer dataset"
      ],
      "metadata": {
        "id": "9mJdx-jlKLH4"
      },
      "id": "9mJdx-jlKLH4"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data from sklearn\n",
        "breast_cancer_dataset = sklearn.datasets.load_breast_cancer()"
      ],
      "metadata": {
        "id": "_lmdeZiLJdGm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_lmdeZiLJdGm"
    },
    {
      "cell_type": "code",
      "source": [
        "print(breast_cancer_dataset)"
      ],
      "metadata": {
        "id": "xeMBIvC_Osi4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "xeMBIvC_Osi4"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data to a data frame\n",
        "data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)"
      ],
      "metadata": {
        "id": "W7M3RUdbLUX-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "W7M3RUdbLUX-"
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 rows of the dataframe\n",
        "data_frame.head()"
      ],
      "metadata": {
        "id": "i8vFSlhGO8MX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "i8vFSlhGO8MX"
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the 'target' column to the data frame\n",
        "data_frame['label'] = breast_cancer_dataset.target"
      ],
      "metadata": {
        "id": "l4e-F1dtO6A0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "l4e-F1dtO6A0"
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 rows of the dataframe\n",
        "data_frame.head()"
      ],
      "metadata": {
        "id": "xfNdayWSPCNm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "xfNdayWSPCNm"
    },
    {
      "cell_type": "code",
      "source": [
        "# number of rows and Columns in this dataset\n",
        "data_frame.shape"
      ],
      "metadata": {
        "id": "qndV2eAUMXBY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qndV2eAUMXBY"
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for missing values\n",
        "data_frame.isnull().sum()"
      ],
      "metadata": {
        "id": "IL8LKwztPJpX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "IL8LKwztPJpX"
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of Target Varibale\n",
        "data_frame['label'].value_counts()"
      ],
      "metadata": {
        "id": "3XQHYCMwOZlF"
      },
      "execution_count": null,
      "outputs": [],
      "id": "3XQHYCMwOZlF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 --> Benign\n",
        "\n",
        "0 --> Malignant"
      ],
      "metadata": {
        "id": "_WOK1rw1MeGZ"
      },
      "id": "_WOK1rw1MeGZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separating the features and target"
      ],
      "metadata": {
        "id": "EJobdKlfPaW_"
      },
      "id": "EJobdKlfPaW_"
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_frame.drop(columns='label', axis=1)\n",
        "Y = data_frame['label']"
      ],
      "metadata": {
        "id": "-BRF89ESMZUU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "-BRF89ESMZUU"
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "pNKv8fdZPeDx"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pNKv8fdZPeDx"
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "id": "tKTKvhRgPeyc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "tKTKvhRgPeyc"
    },
    {
      "cell_type": "code",
      "source": [
        " X = np.asarray(X)\n",
        " Y = np.asarray(Y)"
      ],
      "metadata": {
        "id": "4OFJBpqfTCjJ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4OFJBpqfTCjJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GridSearchCV**\n",
        "- Give parameters according to model\n",
        "- classifier = GridSearchCV(model, parameters, cv=5)\n",
        "- classifier.fit x and y\n",
        "- classifier.best_score_\n",
        "- classifier.best_params_\n",
        "- classifier.cv_results_"
      ],
      "metadata": {
        "id": "oRZT0lOjDFYv"
      },
      "id": "oRZT0lOjDFYv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is used for determining the best parameters for our model\n",
        "- All Combination of hyperparameters lega\n",
        "- Kernel Type\n",
        "- C value c less means clear cut hyperplane divide data that way - overfitting issue c value more underfitting -> thoda mismatch output ka ho sakta\n",
        "\n",
        "- Cv -> Number of folds while training model KFOLD"
      ],
      "metadata": {
        "id": "FCspxr1DDJe2"
      },
      "id": "FCspxr1DDJe2"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the SVC model\n",
        "model = SVC()"
      ],
      "metadata": {
        "id": "r3rh8uIy9p2D"
      },
      "execution_count": null,
      "outputs": [],
      "id": "r3rh8uIy9p2D"
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "\n",
        "parameters = {\n",
        "              'kernel':['linear','poly','rbf','sigmoid'],\n",
        "              'C':[1, 5, 10, 20]\n",
        "}"
      ],
      "metadata": {
        "id": "M540T5NKDcM5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "M540T5NKDcM5"
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search\n",
        "classifier = GridSearchCV(model, parameters, cv=5)"
      ],
      "metadata": {
        "id": "29CM6hFKD6dQ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "29CM6hFKD6dQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the data to our model\n",
        "classifier.fit(X, Y)"
      ],
      "metadata": {
        "id": "oN9suJpLEzrN"
      },
      "execution_count": null,
      "outputs": [],
      "id": "oN9suJpLEzrN"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.cv_results_"
      ],
      "metadata": {
        "id": "bqkaZYkBFGUA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bqkaZYkBFGUA"
    },
    {
      "cell_type": "code",
      "source": [
        "# best parameters\n",
        "\n",
        "best_parameters = classifier.best_params_\n",
        "print(best_parameters)"
      ],
      "metadata": {
        "id": "gY2z0CWNGIjB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "gY2z0CWNGIjB"
    },
    {
      "cell_type": "code",
      "source": [
        "# higest accuracy\n",
        "\n",
        "highest_accuracy = classifier.best_score_\n",
        "print(highest_accuracy)"
      ],
      "metadata": {
        "id": "i0LbbSLRGgy8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "i0LbbSLRGgy8"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the results to pandas dataframe\n",
        "result = pd.DataFrame(classifier.cv_results_)"
      ],
      "metadata": {
        "id": "3_g9aue0Fqzg"
      },
      "execution_count": null,
      "outputs": [],
      "id": "3_g9aue0Fqzg"
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "id": "ki2MjrG5G5Xq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ki2MjrG5G5Xq"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extract specific columns (e.g., 'column1' and 'column2') and combine into a new DataFrame\n",
        "# new_df = result[['column1', 'column2']]\n",
        "grid_search_result = result[['param_C','param_kernel','mean_test_score']]"
      ],
      "metadata": {
        "id": "FEVlRsUdG7MO"
      },
      "execution_count": null,
      "outputs": [],
      "id": "FEVlRsUdG7MO"
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_result"
      ],
      "metadata": {
        "id": "vSNtss-uHcgc"
      },
      "execution_count": null,
      "outputs": [],
      "id": "vSNtss-uHcgc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highest Accuracy = 95.2%\n",
        "\n",
        "Best Parameters = {'C':10, 'kernel':'linear'}"
      ],
      "metadata": {
        "id": "IWOCmBUlH0YY"
      },
      "id": "IWOCmBUlH0YY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**RandomizedSearchCV**\n",
        "- same classifier syntax as GridSearch\n",
        "- classifier = RandomizedSearchCV(model, parameters, cv=5) syntax difference"
      ],
      "metadata": {
        "id": "7-zu3K_pIG_8"
      },
      "id": "7-zu3K_pIG_8"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the SVC model\n",
        "model = SVC()"
      ],
      "metadata": {
        "id": "Z0joe7YZHicX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Z0joe7YZHicX"
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "\n",
        "parameters = {\n",
        "              'kernel':['linear','poly','rbf','sigmoid'],\n",
        "              'C':[1, 5, 10, 20]\n",
        "}"
      ],
      "metadata": {
        "id": "eErxWMm7Id54"
      },
      "execution_count": null,
      "outputs": [],
      "id": "eErxWMm7Id54"
    },
    {
      "cell_type": "code",
      "source": [
        "# grid search\n",
        "classifier = RandomizedSearchCV(model, parameters, cv=5)"
      ],
      "metadata": {
        "id": "Pn8DCbA2Ig-m"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Pn8DCbA2Ig-m"
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the data to our model\n",
        "classifier.fit(X, Y)"
      ],
      "metadata": {
        "id": "UI4p-l5RIruS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UI4p-l5RIruS"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.cv_results_"
      ],
      "metadata": {
        "id": "QiZso2A2IwKA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QiZso2A2IwKA"
    },
    {
      "cell_type": "code",
      "source": [
        "# best parameters\n",
        "\n",
        "best_parameters = classifier.best_params_\n",
        "print(best_parameters)"
      ],
      "metadata": {
        "id": "OJDZTK_wIz2Z"
      },
      "execution_count": null,
      "outputs": [],
      "id": "OJDZTK_wIz2Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# higest accuracy\n",
        "\n",
        "highest_accuracy = classifier.best_score_\n",
        "print(highest_accuracy)"
      ],
      "metadata": {
        "id": "xnq8i9XSI-_-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "xnq8i9XSI-_-"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the results to pandas dataframe\n",
        "result = pd.DataFrame(classifier.cv_results_)"
      ],
      "metadata": {
        "id": "v6NCme_2I-__"
      },
      "execution_count": null,
      "outputs": [],
      "id": "v6NCme_2I-__"
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "id": "7obRN-VLI-__"
      },
      "execution_count": null,
      "outputs": [],
      "id": "7obRN-VLI-__"
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_search_result = result[['param_C','param_kernel','mean_test_score']]"
      ],
      "metadata": {
        "id": "pTZ5a24WI_AA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pTZ5a24WI_AA"
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_search_result"
      ],
      "metadata": {
        "id": "C_exY6JXI_AA"
      },
      "execution_count": null,
      "outputs": [],
      "id": "C_exY6JXI_AA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highest Accuracy = 95.2%\n",
        "\n",
        "Best Parameters = {'C':10, 'kernel':'linear'}"
      ],
      "metadata": {
        "id": "8TtW4xvJJn_9"
      },
      "id": "8TtW4xvJJn_9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "- Accuracy_score\n",
        "  - from sklearn.metrics import accuracy_score\n",
        "  - accuracy_score(Y_train, X_train_prediction)\n",
        "- Confusion matrix\n",
        "  - from sklearn.metrics import confusion_matrix\n",
        "  - confusion_matrix(Y_test, X_test_prediction)\n",
        "  - tn, fp, fn, tp = cf_matrix.ravel()\n",
        "- Precision, Recall, F1 Score"
      ],
      "metadata": {
        "id": "yWeOa_hZWOYy"
      },
      "id": "yWeOa_hZWOYy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTb-9TFFqprC"
      },
      "source": [
        "Importing the Dependencies"
      ],
      "id": "aTb-9TFFqprC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q9U3S_whh3-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "3q9U3S_whh3-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egMd5zeurTMR"
      },
      "source": [
        "Data Collection and Processing"
      ],
      "id": "egMd5zeurTMR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q-3-LkQrREV"
      },
      "source": [
        "# loading the csv data to a Pandas DataFrame\n",
        "heart_data = pd.read_csv('/content/heart_disease_data.csv')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0q-3-LkQrREV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8dQxSTqriWD"
      },
      "source": [
        "# print first 5 rows of the dataset\n",
        "heart_data.head()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "M8dQxSTqriWD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx_aCZDgrqdR"
      },
      "source": [
        "# print last 5 rows of the dataset\n",
        "heart_data.tail()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "Fx_aCZDgrqdR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nX1tIzbrz0u"
      },
      "source": [
        "# number of rows and columns in the dataset\n",
        "heart_data.shape"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8nX1tIzbrz0u"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_xTcw1Sr6aJ"
      },
      "source": [
        "# getting some info about the data\n",
        "heart_data.info()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "7_xTcw1Sr6aJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjHtW31rsGlb"
      },
      "source": [
        "# checking for missing values\n",
        "heart_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "GjHtW31rsGlb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHmcP7DJsSEP"
      },
      "source": [
        "# statistical measures about the data\n",
        "heart_data.describe()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "OHmcP7DJsSEP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4InaOSIUsfWP"
      },
      "source": [
        "# checking the distribution of Target Variable\n",
        "heart_data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4InaOSIUsfWP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSOBu4qDtJy5"
      },
      "source": [
        "1 --> Defective Heart\n",
        "\n",
        "0 --> Healthy Heart"
      ],
      "id": "aSOBu4qDtJy5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW8i4igjtPRC"
      },
      "source": [
        "Splitting the Features and Target"
      ],
      "id": "tW8i4igjtPRC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6yfbswrs7m3"
      },
      "source": [
        "X = heart_data.drop(columns='target', axis=1)\n",
        "Y = heart_data['target']"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "Q6yfbswrs7m3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJoCp4ZKtpZy"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "XJoCp4ZKtpZy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nukuj-YItq1w"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "nukuj-YItq1w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EcjSE3Et18n"
      },
      "source": [
        "Splitting the Data into Training data & Test Data"
      ],
      "id": "_EcjSE3Et18n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-UUfRUxtuga"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a-UUfRUxtuga"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7PrjC6zuf6X"
      },
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "x7PrjC6zuf6X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beSkZmpVuvn9"
      },
      "source": [
        "Model Training"
      ],
      "id": "beSkZmpVuvn9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Md74FYuqNL"
      },
      "source": [
        "model = LogisticRegression(max_iter=1000)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4-Md74FYuqNL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCdHYxGUu7XD"
      },
      "source": [
        "# training the LogisticRegression model with Training data\n",
        "model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "kCdHYxGUu7XD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYIw8Gi9vXfU"
      },
      "source": [
        "Model Evaluation"
      ],
      "id": "ZYIw8Gi9vXfU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmxAekfZvZa9"
      },
      "source": [
        "### 1-**Accuracy Score**"
      ],
      "id": "wmxAekfZvZa9"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "aMMAnoWYFQY5"
      },
      "execution_count": null,
      "outputs": [],
      "id": "aMMAnoWYFQY5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g19JaUTMvPKy"
      },
      "source": [
        "# accuracy on training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
        "print(training_data_accuracy)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "g19JaUTMvPKy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQBZvBh8v7R_"
      },
      "source": [
        "print('Accuracy on Training data : ', round(training_data_accuracy*100, 2), '%')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "uQBZvBh8v7R_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDONDJdlwBIO"
      },
      "source": [
        "# accuracy on test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
        "print(test_data_accuracy)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "mDONDJdlwBIO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MBS-OqdwYpf"
      },
      "source": [
        "print('Accuracy on Test data : ', round(test_data_accuracy*100, 2), '%')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "_MBS-OqdwYpf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2- **Confusion Matrix**"
      ],
      "metadata": {
        "id": "hOqOj3xEEqvW"
      },
      "id": "hOqOj3xEEqvW"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "pZSEUHp7Eqcr"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pZSEUHp7Eqcr"
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(Y_test, X_test_prediction)\n",
        "\n",
        "print(cf_matrix)"
      ],
      "metadata": {
        "id": "cXkoIIujFeQn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "cXkoIIujFeQn"
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = cf_matrix.ravel()\n",
        "\n",
        "print(tn, fp, fn, tp)"
      ],
      "metadata": {
        "id": "tpmo_nY8FyZl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "tpmo_nY8FyZl"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cf_matrix, annot=True)"
      ],
      "metadata": {
        "id": "i4ffPhNZGBR_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "i4ffPhNZGBR_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "confusion matrix for multi class classification: https://colab.research.google.com/drive/17FViiMJbJXQ5s9GOW94emoHcCKUcYr3l?usp=sharing"
      ],
      "metadata": {
        "id": "yFibQac0G4fh"
      },
      "id": "yFibQac0G4fh"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fr6QfOeqGr_3"
      },
      "execution_count": null,
      "outputs": [],
      "id": "fr6QfOeqGr_3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3- **Precision  Recall and F1 Score**\n",
        "- Precision is the ratio of number of True Positive to the total number of Predicted Positive. It measures, out of the total predicted positive, how many are actually positive.\n",
        "- Recall is the ratio of number of True Positive to the total number of Actual Positive. It measures, out of the total actual positive, how many are predicted as True Positive.\n",
        "- F1 Score is an important evaluation metric for binary classification that combines Precision & Recall. F1 Score is the harmonic mean of Precision & Recall."
      ],
      "metadata": {
        "id": "EbXOkMQqUtRR"
      },
      "id": "EbXOkMQqUtRR"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "LBqZ_bqTU60x"
      },
      "id": "LBqZ_bqTU60x",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training data predictions\n",
        "precision_train = precision_score(Y_train, X_train_prediction)\n",
        "print('Training data Precision =', precision_train)\n",
        "recall_train = recall_score(Y_train, X_train_prediction)\n",
        "print('Training data Recall =', recall_train)\n",
        "f1_score_train = f1_score(Y_train, X_train_prediction)\n",
        "print('Training data F1 Score =', f1_score_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqB-VrjTVFJJ",
        "outputId": "4bf4baae-f9cc-4a49-8faf-3e958a13909b"
      },
      "id": "mqB-VrjTVFJJ",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data Precision = 0.8299319727891157\n",
            "Training data Recall = 0.9242424242424242\n",
            "Training data F1 Score = 0.8745519713261649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test data predictions\n",
        "precision_test = precision_score(Y_test, X_test_prediction)\n",
        "print('Test data Precision =', precision_test)\n",
        "recall_test = recall_score(Y_test, X_test_prediction)\n",
        "print('Test data Recall =', recall_test)"
      ],
      "metadata": {
        "id": "r5sjige9VOTF"
      },
      "id": "r5sjige9VOTF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy ML Model -\n",
        "1.  FastAPI\n",
        "2.  Ngrok\n",
        "3. Heroku\n",
        "\n"
      ],
      "metadata": {
        "id": "ztWY_so8WVQn"
      },
      "id": "ztWY_so8WVQn"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFQih2ibWbxz"
      },
      "id": "WFQih2ibWbxz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}